{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#torchradio","title":"Torchradio","text":"<p>Torchradio is a Python library for building differentiable RF simulations.</p> <p>[!NOTE] Torchradio is not affiliated with the official PyTorch project.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install torchradio\n</code></pre>"},{"location":"#example","title":"Example","text":"<p>Below is a simple example that trains two radios via backpropagation to communicate over the same noisy channel:</p> <pre><code># Define the training environment\nfrom torchradio import Transmitter, Receiver\nfrom torchradio.algorithm.example import DenseRadio\nfrom torchradio.env.null import RandomAWGNEnvironment\n\nn_radios = 2\nradio0 = DenseRadio(n_input_bits=8, tx_length_per_bit=4)\nradio1 = DenseRadio(n_input_bits=8, tx_length_per_bit=4)\nenv = RandomAWGNEnvironment(p_min=0, p_max=1)\nenv.place(\n    transmitters={\"tx0\": Transmitter(radio0.tx), \"tx1\": Transmitter(radio1.tx)},\n    receivers={\"rx0\": Receiver(radio0.rx), \"rx1\": Receiver(radio1.rx)},\n)\n\n\n# Evaluate the initial radios\nimport numpy as np\n\ndef evaluate():\n    simulation_logs = env.simulate(n_timesteps=10000, batch_size=10)\n    tx_bits = {k: v.metadata[\"bits\"] for k, v in simulation_logs.tx.items()}\n    rx_bits = {k: v[\"bits\"] for k, v in simulation_logs.rx.items()}\n    for i in range(n_radios):\n        print(f'radio{i} BER: {1 - float(np.mean((tx_bits[f\"tx{i}\"] == rx_bits[f\"rx{i}\"]).numpy())):.5f}')\n\nevaluate()\n\n\n# Define the training loop\nimport torch\nfrom torch import nn\n\nloss_fn = nn.BCELoss()\noptimizer = torch.optim.Adam([*radio0.parameters(), *radio1.parameters()])\n\ndef train(\n    n_timesteps: int,\n    batch_size: int,\n) -&gt; float:\n    optimizer.zero_grad()\n    device_logs = env.simulate(n_timesteps, batch_size)\n    tx_bits = {k: v.metadata[\"bits\"] for k, v in device_logs.tx.items()}\n    rx_outputs = {k: v[\"bit_probabilities\"] for k, v in device_logs.rx.items()}\n    loss = sum([\n        loss_fn(rx_outputs[f\"rx{i}\"], tx_bits[f\"tx{i}\"].float())\n        for i in range(n_radios)\n    ])\n    loss.backward()\n    optimizer.step()\n    return loss\n\n\n# Train the radios\nfor i in range(1000):\n    loss = train(n_timesteps=64, batch_size=10)\n    if i % 100 == 0:\n        print(f\"Loss at iteration {i}: {loss:5f}\")\n\n\n# Evaluate the trained radios\nevaluate()\n</code></pre> <p>See our notebooks for more in-depth examples.</p>"},{"location":"#assumptions","title":"Assumptions","text":"<ul> <li>All events take place at baseband.</li> <li>All devices have the same centre frequency and bandwidth.</li> <li>Torchradio is not intended to replace a high-fidelity simulation. Rather, it is a training ground for developing novel radios. If a radio looks promising, its parameters can be exported for testing in a high-fidelity simulation environment.</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>New contributors are always welcome! If you would like to contribute, it is recommended you set up your development environment using the following instructions.</p> <p>Create a new Python virtual environment using your method of choice (e.g., venv, conda, pyenv etc.). Clone this repository and install using</p> <pre><code>pip install -e .[dev]\n</code></pre> <p>The above command will install Torchradio along with its core dependencies, as well as dev-specific dependencies for formatting, linting and testing. The <code>-e</code> flag installs Torchradio in editable mode, so you can quickly see the effects of local source code changes without reinstalling Torchradio. You can test that everything is working as expected by running</p> <pre><code>pytest\n</code></pre> <p>To save failing GitHub Actions due to styling issues, set up the project's git hooks using:</p> <pre><code>pre-commit install\npre-commit run --all-files\n</code></pre> <p>You can view the documentation locally anytime by running:</p> <pre><code>mkdocs serve\n</code></pre>"},{"location":"API/devices/","title":"Devices","text":"<p>A device pairs a <code>TransmissionAlgorithm</code> or a <code>ReceptionAlgorithm</code> with other physical characteristics.</p>"},{"location":"API/devices/#torchradio.device.Device","title":"<code>Device</code>","text":"<p>The base <code>Device</code> class consists of a <code>SpatialDistribution</code> that is sampled whenever the device is placed in an environment.</p>"},{"location":"API/devices/#torchradio.device.Device.spatial_distribution","title":"<code>spatial_distribution: SpatialDistribution</code>  <code>property</code>","text":"<p>Get the device's spatial distribution.</p> <p>Returns     The device's spatial distribution.</p>"},{"location":"API/devices/#torchradio.device.Device.__init__","title":"<code>__init__(spatial_distribution=None)</code>","text":"<p>Create a new device with a <code>spatial_distribution</code>.</p> <p>Parameters:</p> Name Type Description Default <code>spatial_distribution</code> <code>SpatialDistribution | None</code> <p>A <code>Callable</code> that randomly samples <code>Position</code>s. Defaults to None. If None, a null <code>SpatialDistribution</code> is used, which always returns <code>Position(x=0, y=0, z=0)</code>.</p> <code>None</code>"},{"location":"API/devices/#torchradio.device.Device.place","title":"<code>place()</code>","text":"<p>Sample a <code>Position</code> from the device's spatial distribution.</p> <p>Returns     A <code>Position</code> randomly sampled according to the device's spatial distribution.</p>"},{"location":"API/devices/#torchradio.device.Receiver","title":"<code>Receiver</code>","text":"<p>               Bases: <code>Device</code></p> <p>A <code>Device</code> that receives signals from the environment.</p>"},{"location":"API/devices/#torchradio.device.Receiver.__call__","title":"<code>__call__(signal)</code>","text":"<p>Invoke the underlying <code>ReceptionAlgorithm</code> to produce a <code>Reception</code> dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>Tensor</code> <p>Input signal from the environment.</p> required <p>Returns:</p> Type Description <code>Reception</code> <p>A dictionary the summarizes various aspects of the received signal. Common keys for reconstructive receivers include 'bit_probabilities' and 'bits'.</p>"},{"location":"API/devices/#torchradio.device.Receiver.__init__","title":"<code>__init__(algorithm, spatial_distribution=None)</code>","text":"<p>Create a new <code>Receiver</code> from an algorithm and a spatial distribution.</p> <p>Parameters:</p> Name Type Description Default <code>algorithm</code> <code>ReceptionAlgorithm</code> <p>A <code>Callable</code> that produces <code>Receptions</code>s.</p> required <code>spatial_distribution</code> <code>SpatialDistribution | None</code> <p>A <code>Callable</code> that randomly samples <code>Position</code>s. Defaults to None. If None, a null <code>SpatialDistribution</code> is used, which always returns <code>Position(x=0, y=0, z=0)</code>.</p> <code>None</code>"},{"location":"API/devices/#torchradio.device.Receiver.parameters","title":"<code>parameters()</code>","text":"<p>Get the receiver's trainable parameters.</p> <p>Returns     The receiver's trainable parameters. An empty iterator is returned if the         receiever does not have trainable parameters.</p>"},{"location":"API/devices/#torchradio.device.Transmitter","title":"<code>Transmitter</code>","text":"<p>               Bases: <code>Device</code></p> <p>A <code>Device</code> that transmits signals into the environment.</p>"},{"location":"API/devices/#torchradio.device.Transmitter.__call__","title":"<code>__call__(n_timesteps, batch_size=1)</code>","text":"<p>Invoke the underlying <code>TransmissionAlgorithm</code> to produce a <code>Tranmission</code>.</p> <p>Parameters:</p> Name Type Description Default <code>n_timesteps</code> <code>int</code> <p>Number of timesteps to transmit for.</p> required <code>batch_size</code> <code>int</code> <p>How many simulations to conduct in parallel.</p> <code>1</code> <p>Returns:</p> Type Description <code>Transmission</code> <p>A <code>Transmission</code> with a complex-valued signal with shape <code>[batch_size, n_timesteps]</code>.</p>"},{"location":"API/devices/#torchradio.device.Transmitter.__init__","title":"<code>__init__(algorithm, spatial_distribution=None, max_gain=None)</code>","text":"<p>Create a new <code>Transmitter</code> from an algorithm and a spatial distribution.</p> <p>Parameters:</p> Name Type Description Default <code>algorithm</code> <code>TransmissionAlgorithm</code> <p>A <code>Callable</code> that produces <code>Transmission</code>s.</p> required <code>spatial_distribution</code> <code>SpatialDistribution | None</code> <p>A <code>Callable</code> that randomly samples <code>Position</code>s. Defaults to None. If None, a null <code>SpatialDistribution</code> is used, which always returns <code>Position(x=0, y=0, z=0)</code>.</p> <code>None</code> <code>max_gain</code> <code>float | None</code> <p>A saturation limit on transmissions. The real and imaginary components of transmitted signals are capped to <code>max_gain</code>.</p> <code>None</code>"},{"location":"API/devices/#torchradio.device.Transmitter.parameters","title":"<code>parameters()</code>","text":"<p>Get the transmitter's trainable parameters.</p> <p>Returns     The transmitter's trainable parameters. An empty iterator is returned if the         transmitter does not have trainable parameters.</p>"},{"location":"API/position/","title":"Position","text":"<p>Groups together common classes and functions for randomly sampling physical device positions in environments.</p>"},{"location":"API/position/#torchradio.position.Position","title":"<code>Position</code>  <code>dataclass</code>","text":"<p>A concrete instantiation of a device's position in the environment.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float</code> <p>x coordinate</p> required <code>y</code> <code>float</code> <p>y coordinate</p> required <code>z</code> <code>float</code> <p>z coordinate</p> required"},{"location":"API/position/#torchradio.position.SpatialDistribution","title":"<code>SpatialDistribution</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>All devices are required to include a <code>SpatialDistribution</code>.</p> <p>A <code>SpatialDistribution</code> is any <code>Callable</code> returns a randomly sampled <code>Position</code> each time it is invoked.</p>"},{"location":"API/position/#torchradio.position.SpatialDistribution.__call__","title":"<code>__call__()</code>","text":"<p>Randomly sample a <code>Position</code> from an underlying distribution.</p> <p>Returns     A randomly sampled <code>Position</code>.</p>"},{"location":"API/position/#torchradio.position.get_null_distribution","title":"<code>get_null_distribution(x=0, y=0, z=0)</code>","text":"<p>Get a trivial or (null) <code>SpatialDistribution</code> that always samples the same <code>Position</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float</code> <p>x coordinate</p> <code>0</code> <code>y</code> <code>float</code> <p>y coordinate</p> <code>0</code> <code>z</code> <code>float</code> <p>z coordinate</p> <code>0</code> <p>Returns:</p> Type Description <code>SpatialDistribution</code> <p>A <code>SpatialDistribution</code> that always returns the same <code>Position</code> as described by <code>x</code>, <code>y</code> and <code>z</code>.</p> Example <pre><code>&gt;&gt;&gt; distribution = get_null_distribution(1, 2)\n&gt;&gt;&gt; distribution()\nPosition(x=1, y=2, z=0)\n</code></pre>"},{"location":"API/position/#torchradio.position.get_uniform_distribution","title":"<code>get_uniform_distribution(x_bounds, y_bounds, z_bounds)</code>","text":"<p>Get a <code>SpatialDistribution</code> that samples uniformly from some 3D bounds.</p> <p>Parameters:</p> Name Type Description Default <code>x_bounds</code> <code>tuple[float, float]</code> <p>Desired interval for the x coordinate</p> required <code>y_bounds</code> <code>tuple[float, float]</code> <p>Desired interval for the y coordinate</p> required <code>z_bounds</code> <code>tuple[float, float]</code> <p>Desired interval for the z coordinate</p> required <p>Returns:</p> Type Description <code>SpatialDistribution</code> <p>A <code>SpatialDistribution</code> that returns a uniformly-sampled <code>Position</code> according to the provided bounds.</p> Example <pre><code>&gt;&gt;&gt; distribution = get_uniform_distribution((0, 10), (0, 10), (0, 5))\n&gt;&gt;&gt; distribution()\nPosition(x=9.82526, y=1.6853619, z=1.1326883)\n</code></pre> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>bounds[1] &lt; bounds[0]</code>.</p>"},{"location":"API/types/","title":"Types","text":"<p>Defines the core types used throughout Torchradio.</p>"},{"location":"API/types/#torchradio.types.COMPLEX_DTYPE","title":"<code>COMPLEX_DTYPE = torch.complex64</code>  <code>module-attribute</code>","text":"<p>The common datatype for all complex tensors in Torchradio.</p>"},{"location":"API/types/#torchradio.types.Reception","title":"<code>Reception = dict[str, torch.Tensor]</code>  <code>module-attribute</code>","text":"<p>The <code>ReceptionAlgorithm</code> author is free to capture whatever fields are required for downstream loss functions. A <code>Reception</code> is the receiver analogue of <code>Transmission.metadata</code>.</p>"},{"location":"API/types/#torchradio.types.DeviceLogs","title":"<code>DeviceLogs</code>  <code>dataclass</code>","text":"<p>Captures the <code>Transmission</code> and <code>Reception</code> logs from a simulation run.</p> <p>Each <code>Transmission</code> and <code>Reception</code> is associated with a device name.</p> <p>Parameters:</p> Name Type Description Default <code>tx</code> <code>dict[str, Transmission]</code> <p>Maps device names to <code>Transmission</code>s.</p> required <code>rx</code> <code>dict[str, Reception]</code> <p>Maps device names to <code>Reception</code>s.</p> required"},{"location":"API/types/#torchradio.types.ReceptionAlgorithm","title":"<code>ReceptionAlgorithm</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>All receivers in Torchradio are required to implement a <code>ReceptionAlgorithm</code>.</p> <p>A <code>ReceptionAlgorithm</code> is any <code>Callable</code> that produces a <code>Reception</code> from an input <code>signal</code>.</p>"},{"location":"API/types/#torchradio.types.ReceptionAlgorithm.__call__","title":"<code>__call__(signal)</code>","text":"<p>Return a <code>Reception</code> from a complex-valued input <code>signal</code>.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>Tensor</code> <p>A complex-valued input tensor from the environment.</p> required <p>Returns:</p> Type Description <code>Reception</code> <p>A <code>Reception</code> with that maps each key to a <code>torch.Tensor</code> for downstream loss functions.</p>"},{"location":"API/types/#torchradio.types.Transmission","title":"<code>Transmission</code>  <code>dataclass</code>","text":"<p>The core output type for any transmitter. A <code>Transmission</code> consists of two parts: a signal and a metadata dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>Tensor</code> <p>A complex-valued tensor that is propagated into the environment</p> required <code>metadata</code> <code>dict[str, Tensor]</code> <p>Used to record arbitrary information that can be used by downstream loss functions. The most commonly used metadata key is 'bits' to capture the bits before the <code>TransmissionAlgortihm</code> produces an output signal.</p> required"},{"location":"API/types/#torchradio.types.TransmissionAlgorithm","title":"<code>TransmissionAlgorithm</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>All transmitters in Torchradio are required to implement a <code>TransmissionAlgorithm</code>.</p> <p>A <code>TransmissionAlgorithm</code> is any <code>Callable</code> that produces a <code>Transmission</code> with a complex-valued <code>signal</code> with shape <code>[batch_size, n_timesteps]</code>.</p>"},{"location":"API/types/#torchradio.types.TransmissionAlgorithm.__call__","title":"<code>__call__(n_timesteps, batch_size)</code>","text":"<p>Return a <code>Transmission</code> given <code>n_timesteps</code> and <code>batch_size</code>.</p> <p>Parameters:</p> Name Type Description Default <code>n_timesteps</code> <code>int</code> <p>Number of timesteps to simulate.</p> required <code>batch_size</code> <code>int</code> <p>How many batches to yield.</p> required <p>Returns:</p> Type Description <code>Transmission</code> <p>A <code>Transmission</code> with a complex-valued signal with shape <code>[batch_size, n_timesteps]</code>.</p>"},{"location":"API/Algorithms/0_null/","title":"Null Algorithms","text":"<p>Simple (null) transmitters for testing and debugging.</p>"},{"location":"API/Algorithms/0_null/#torchradio.algorithm.null.get_constant_transmission_algorithm","title":"<code>get_constant_transmission_algorithm(val)</code>","text":"<p>Get a basic transmission algorithm that output a constant complex value.</p> <p>Parameters:</p> Name Type Description Default <code>val</code> <code>complex | Parameter</code> <p>constant complex value to transmit</p> required <p>Returns:</p> Type Description <code>TransmissionAlgorithm</code> <p>A <code>TransmissionAlgorithm</code> that outputs a tensor where every element is <code>val</code>.</p> Example <pre><code>&gt;&gt;&gt; tx = get_constant_transmitter(1 + 1j)\n&gt;&gt;&gt; tx(5, 2)\nTransmission(signal=tensor([[1.+1.j, 1.+1.j, 1.+1.j, 1.+1.j, 1.+1.j],\n        [1.+1.j, 1.+1.j, 1.+1.j, 1.+1.j, 1.+1.j]]), metadata={})\n</code></pre>"},{"location":"API/Algorithms/0_null/#torchradio.algorithm.null.get_null_reception_algorithm","title":"<code>get_null_reception_algorithm()</code>","text":"<p>Get a null reception algorithm that does not do any processing,.</p> <p>Returns:</p> Type Description <code>ReceptionAlgorithm</code> <p>A null <code>ReceptionAlgorithm</code> that outputs an empty <code>Reception</code> dictionary.</p> Example <pre><code>&gt;&gt;&gt; rx = get_null_reception_algorithm()\n&gt;&gt;&gt; signal = torch.zeros([2, 5], dtype=torch.complex64)\n&gt;&gt;&gt; rx(signal)\n{}\n</code></pre>"},{"location":"API/Algorithms/0_null/#torchradio.algorithm.null.get_null_transmission_algortihm","title":"<code>get_null_transmission_algortihm()</code>","text":"<p>Get a null transmission algorithm that output nothing.</p> <p>Returns:</p> Type Description <code>TransmissionAlgorithm</code> <p>A <code>TransmissionAlgorithm</code> that outputs a complex-valued tensors of zeros.</p> Example <pre><code>&gt;&gt;&gt; tx = get_null_transmission_algortihm()\n&gt;&gt;&gt; tx(5, 2)\nTransmission(signal=tensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n        [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]]), metadata={})\n</code></pre>"},{"location":"API/Algorithms/1_modem/","title":"Modem Algorithms","text":"<p>Common digital modulation algorithms.</p>"},{"location":"API/Algorithms/1_modem/#torchradio.algorithm.modem.DSSS","title":"<code>DSSS</code>","text":"<p>               Bases: <code>Modem</code></p> <p>Direct-sequence spread spectrum modulation and demodulation.</p> <p>Currently implemented using the third-party <code>commpy</code> library. Note that <code>DSSS</code> does not contain any trainable parameters. <code>DSSS</code> provides compatible <code>tx</code> and <code>rx</code> methods. When defining transmitters and receivers, ensure the corresponding method is passed.</p> Example <pre><code>&gt;&gt;&gt; chip_sequence = torch.randint(0, 2, (4,))  # binary sequence of length 4\n&gt;&gt;&gt; modem = DSSS(chip_sequence)\n&gt;&gt;&gt; env = NullEnvironment()\n&gt;&gt;&gt; env.place({\"tx\": modem.tx}, {\"rx\": modem.rx})\n</code></pre>"},{"location":"API/Algorithms/1_modem/#torchradio.algorithm.modem.DSSS.__init__","title":"<code>__init__(chip_sequence, mode='psk', n_symbols=2, demod_type='hard')</code>","text":"<p>Create a new <code>DSSS</code> radio using either phase-shift keying (PSK) or quadrature amplitude modulation (QAM).</p> <p>Parameters:</p> Name Type Description Default <code>chip_sequence</code> <code>Tensor</code> <p>A binary sequence to spread the input bits with.</p> required <code>mode</code> <code>str</code> <p>Modulation mode. Must be either \"psk\" or \"qam\".</p> <code>'psk'</code> <code>n_symbols</code> <code>int</code> <p>Number of symbols to use for modulation. If <code>mode == \"psk\",</code>n_symbols<code>must be a power of 2. If</code>mode == \"qam\"<code>,</code>n_symbols` must be a power of 2 and square.</p> <code>2</code> <code>demod_type</code> <code>str</code> <p>\"hard\" or \"soft\" decision boundary for bit demodulation.</p> <code>'hard'</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>mode not in [\"psk\", \"qam\"]</code>.</p> <code>ValueError</code> <p>If <code>n_symbols</code> is not a power of 2 or square (square only required for <code>mode == \"qam\"</code>).</p> <code>ValueError</code> <p>If <code>demod_type not in [\"hard\", \"soft\"]</code>.</p> <code>NotImplementedError</code> <p>If <code>demod_type == \"soft\"</code>.</p>"},{"location":"API/Algorithms/1_modem/#torchradio.algorithm.modem.DSSS.rx","title":"<code>rx(signal)</code>","text":"<p>Demodulates and despreads an input signal.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>Tensor</code> <p>A 2D complex valued input tensor.</p> required <p>Returns:</p> Type Description <code>Reception</code> <p>A <code>Reception</code> dictionary that records the decoded bits using the key \"bits\".</p>"},{"location":"API/Algorithms/1_modem/#torchradio.algorithm.modem.DSSS.tx","title":"<code>tx(n_timesteps, batch_size=1)</code>","text":"<p>Encode randomly generated bits with a chip sequence before modulating using commpy.Modem.</p> <p>Parameters:</p> Name Type Description Default <code>n_timesteps</code> <code>int</code> <p>How many timesteps to transmit for.</p> required <code>batch_size</code> <code>int</code> <p>How many transmissions to create in parallel.</p> <code>1</code> <p>Returns:</p> Type Description <code>Transmission</code> <p>A <code>Transmission</code> with a complex-valued signal tensor with shape <code>[n_timesteps, batch_size]</code> and a <code>metadata</code> dictionary that records the transmitted bits using the key \"bits\".</p>"},{"location":"API/Algorithms/1_modem/#torchradio.algorithm.modem.Modem","title":"<code>Modem</code>","text":"<p>Torchradio compatible wrapper for commpy.PSKModem and commpy.QAMModem.</p> <p>Currently implemented using the third-party <code>commpy</code> library. Note that <code>Modem</code> does not contain any trainable parameters. A <code>Modem</code> provides compatible <code>tx</code> and <code>rx</code> methods. When defining transmitters and receivers, ensure the corresponding method is passed.</p> Example <pre><code>&gt;&gt;&gt; modem = Modem(\"psk\", 8)\n&gt;&gt;&gt; env = NullEnvironment()\n&gt;&gt;&gt; env.place({\"tx\": modem.tx}, {\"rx\": modem.rx})\n</code></pre>"},{"location":"API/Algorithms/1_modem/#torchradio.algorithm.modem.Modem.n_input_bits","title":"<code>n_input_bits: int</code>  <code>property</code>","text":"<p>Get number of bits per symbol.</p> <p>Returns     Number of bits per symbol.</p>"},{"location":"API/Algorithms/1_modem/#torchradio.algorithm.modem.Modem.__init__","title":"<code>__init__(mode, n_symbols, demod_type='hard')</code>","text":"<p>Create a new <code>Modem</code> using either phase-shift keying (PSK) or quadrature amplitude modulation (QAM).</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>Modulation mode. Must be either \"psk\" or \"qam\".</p> required <code>n_symbols</code> <code>int</code> <p>Number of symbols to use for modulation. If <code>mode == \"psk\",</code>n_symbols<code>must be a power of 2. If</code>mode == \"qam\"<code>,</code>n_symbols` must be a power of 2 and square.</p> required <code>demod_type</code> <code>str</code> <p>\"hard\" or \"soft\" decision boundary for bit demodulation.</p> <code>'hard'</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>mode not in [\"psk\", \"qam\"]</code>.</p> <code>ValueError</code> <p>If <code>n_symbols</code> is not a power of 2 or square (square only required for <code>mode == \"qam\"</code>).</p> <code>ValueError</code> <p>If <code>demod_type not in [\"hard\", \"soft\"]</code>.</p> <code>NotImplementedError</code> <p>If <code>demod_type == \"soft\"</code>.</p>"},{"location":"API/Algorithms/1_modem/#torchradio.algorithm.modem.Modem.rx","title":"<code>rx(signal)</code>","text":"<p>Demodulates an input signal using a prespecified digital demodulation technique.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>Tensor</code> <p>A 2D complex valued input tensor.</p> required <p>Returns:</p> Type Description <code>Reception</code> <p>A <code>Reception</code> dictionary that records the decoded bits using the key \"bits\".</p>"},{"location":"API/Algorithms/1_modem/#torchradio.algorithm.modem.Modem.tx","title":"<code>tx(n_timesteps, batch_size=1)</code>","text":"<p>Apply digital modulation to randomly generated bits.</p> <p>Parameters:</p> Name Type Description Default <code>n_timesteps</code> <code>int</code> <p>How many timesteps to transmit for.</p> required <code>batch_size</code> <code>int</code> <p>How many transmissions to create in parallel.</p> <code>1</code> <p>Returns:</p> Type Description <code>Transmission</code> <p>A <code>Transmission</code> with a complex-valued signal tensor with shape <code>[n_timesteps, batch_size]</code> and a <code>metadata</code> dictionary that records the transmitted bits using the key \"bits\".</p>"},{"location":"API/Algorithms/example/","title":"Example Trainable Algorithms","text":"<p>Example trainable algorithms to get started with.</p> <p>New users are recommended to use <code>DenseRadio</code> to ensure that input parameters are compatible. A <code>DenseRadio</code> provides compatible <code>tx</code> and <code>rx</code> methods. When defining transmitters and receivers, ensure the corresponding method is passed.</p>"},{"location":"API/Algorithms/example/#torchradio.algorithm.example.DenseRadio","title":"<code>DenseRadio</code>","text":"<p>               Bases: <code>Module</code></p> <p>A convenient wrapper for <code>DenseTransmissionAlgorithm</code> and <code>DenseReceptionAlgorithm</code>.</p> <p><code>DenseRadio</code> guarantees that the underlying <code>TransmissionAlgorithm</code> and <code>ReceptionAlgorithm</code> are compatible. A <code>DenseRadio</code> provides compatible <code>tx</code> and <code>rx</code> methods. When defining transmitters and receivers, ensure the corresponding method is passed.</p> Example <pre><code>&gt;&gt;&gt; radio = DenseRadio(8, 2)\n&gt;&gt;&gt; env = NullEnvironment()\n&gt;&gt;&gt; env.place({\"tx\": radio.tx}, {\"rx\": radio.rx})\n</code></pre>"},{"location":"API/Algorithms/example/#torchradio.algorithm.example.DenseRadio.__init__","title":"<code>__init__(n_input_bits, tx_length_per_bit)</code>","text":"<p>Create a new <code>DenseRadio</code>. See DenseTransmissionAlgorithm.init.</p>"},{"location":"API/Algorithms/example/#torchradio.algorithm.example.DenseRadio.rx","title":"<code>rx(signal)</code>","text":"<p>See <code>DenseReceptionAlgorithm.__call__</code>.</p>"},{"location":"API/Algorithms/example/#torchradio.algorithm.example.DenseRadio.tx","title":"<code>tx(n_timesteps, batch_size=1)</code>","text":"<p>See <code>DenseTransmissionAlgorithm.__call__</code>.</p>"},{"location":"API/Algorithms/example/#torchradio.algorithm.example.DenseReceptionAlgorithm","title":"<code>DenseReceptionAlgorithm</code>","text":"<p>               Bases: <code>Module</code></p> <p>An opinionated <code>ReceptionAlgorithm</code> that uses trainable dense layers.</p> <p>Do not expect this algorithm to be especially performant. It is an example to help users get started with training receivers using <code>Torchradio</code>.</p>"},{"location":"API/Algorithms/example/#torchradio.algorithm.example.DenseReceptionAlgorithm.__call__","title":"<code>__call__(signal)</code>","text":"<p>Apply a series of dense layers an input signal.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>Tensor</code> <p>A 2D complex valued input tensor.</p> required <p>Returns:</p> Type Description <code>Reception</code> <p>A <code>Reception</code> dictionary that records the decoded bits using the key \"bits\", and the probability of each bit under \"bit_probabilities\".</p>"},{"location":"API/Algorithms/example/#torchradio.algorithm.example.DenseReceptionAlgorithm.__init__","title":"<code>__init__(n_bits, window_length)</code>","text":"<p>Create a new <code>DenseReceptionAlgorithm</code>.</p> <p>Parameters:</p> Name Type Description Default <code>n_bits</code> <code>int</code> <p>An input parameter used to shape the number of parameters in the dense layers. Should be compatible with the <code>n_input_bits</code> specified in <code>DenseTransmissionAlgorithm</code>.</p> required <code>window_length</code> <code>int</code> <p>An input parameter used cutoff unused bits from <code>DenseTransmissionAlgorithm</code>. Usually this is set to <code>n_input_bits * tx_length_per_bit</code> from the instantiation of <code>DenseTransmissionAlgorithm</code>.</p> required"},{"location":"API/Algorithms/example/#torchradio.algorithm.example.DenseTransmissionAlgorithm","title":"<code>DenseTransmissionAlgorithm</code>","text":"<p>               Bases: <code>Module</code></p> <p>An opinionated <code>TransmissionAlgorithm</code> that uses trainable dense layers.</p> <p>Do not expect this algorithm to be especially performant. It is an example to help users get started with training transmitters using <code>Torchradio</code>.</p>"},{"location":"API/Algorithms/example/#torchradio.algorithm.example.DenseTransmissionAlgorithm.__call__","title":"<code>__call__(n_timesteps, batch_size=1)</code>","text":"<p>Apply a series of dense layers to randomly generated bits.</p> <p>Parameters:</p> Name Type Description Default <code>n_timesteps</code> <code>int</code> <p>How many timesteps to transmit for.</p> required <code>batch_size</code> <code>int</code> <p>How many transmissions to create in parallel.</p> <code>1</code> <p>Returns:</p> Type Description <code>Transmission</code> <p>A <code>Transmission</code> with a complex-valued signal tensor with shape <code>[n_timesteps, batch_size]</code> and a <code>metadata</code> dictionary that records the transmitted bits using the key \"bits\".</p>"},{"location":"API/Algorithms/example/#torchradio.algorithm.example.DenseTransmissionAlgorithm.__init__","title":"<code>__init__(n_input_bits, tx_length_per_bit)</code>","text":"<p>Create a new <code>DenseTranmissionAlgorithm</code>.</p> <p>Parameters:</p> Name Type Description Default <code>n_input_bits</code> <code>int</code> <p>An input parameter used to shape the number of parameters in the dense layers.</p> required <code>tx_length_per_bit</code> <code>float</code> <p>An input parameter used to shape the number of parameters in the dense layers.</p> required"},{"location":"API/Algorithms/utils/","title":"Utilties","text":"<p>Common helper functions for working with algorithms.</p>"},{"location":"API/Algorithms/utils/#torchradio.algorithm.utils.get_all_parameters","title":"<code>get_all_parameters(transmitters, receivers)</code>","text":"<p>Get the parameters for multiple devices to enable joint optimization.</p> <p>The parameters must be defined as a single iterator to be used with <code>torch.optim</code>.</p> <p>Parameters:</p> Name Type Description Default <code>transmitters</code> <code>Iterable[Transmitter]</code> <p>Transmitters to get parameters from.</p> required <code>receivers</code> <code>Iterable[Receiver]</code> <p>Receivers to get parameters from.</p> required <p>Returns:</p> Type Description <code>Generator[Parameter, None, None]</code> <p>Parameters for all devices as a single iterator.</p>"},{"location":"API/Algorithms/utils/#torchradio.algorithm.utils.get_random_bits","title":"<code>get_random_bits(n_bits, batch_size=1)</code>","text":"<p>Output a random packet of bits.</p> <p>Parameters:</p> Name Type Description Default <code>n_bits</code> <code>int</code> <p>How many bits to output per batch.</p> required <code>batch_size</code> <code>int</code> <p>How many batches to create.</p> <code>1</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>An 0-1 integer valued tensor with shape <code>[batch_size, n_bits]</code>.</p>"},{"location":"API/Environments/base/","title":"Base Environment","text":"<p>Defines the <code>BaseEnvironment</code> that all <code>Torchradio</code> environments are expected to inherit from.</p>"},{"location":"API/Environments/base/#torchradio.env.base.BaseEnvironment","title":"<code>BaseEnvironment</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for <code>Torchradio</code> environments.</p> <p>The core concept behind <code>Torchradio</code> is the use of a common simulation environment that enables backpropagation from the loss function back to the transmitters. It is assumed that all environments used with <code>Torchradio</code> are child classes of <code>BaseEnvironment</code>. The <code>BaseEnvironment</code> automates many common operations, such as device placement, noise simulation and signal aggregation.</p> <p>All child classes of <code>BaseEnvironment</code> are expected to implement the abstract methods: <code>_compute_propagation_parameters</code>, <code>_in_bounds</code>, <code>_propagate</code> and <code>_get_background_noise</code>.</p>"},{"location":"API/Environments/base/#torchradio.env.base.BaseEnvironment.devices","title":"<code>devices: dict[str, dict[str, Position]]</code>  <code>property</code>","text":"<p>Get a dictionary that summarizes the environment's devices with their current positions.</p> <p>Returns     Two maps. One that maps transmitter names to positions and one that maps receiver names to positions.</p>"},{"location":"API/Environments/base/#torchradio.env.base.BaseEnvironment.n_devices","title":"<code>n_devices: int</code>  <code>property</code>","text":"<p>Get current number of devices.</p> <p>Returns     The number of devices placed in the environment.</p>"},{"location":"API/Environments/base/#torchradio.env.base.BaseEnvironment.n_receivers","title":"<code>n_receivers: int</code>  <code>property</code>","text":"<p>Get current number of receivers.</p> <p>Returns     The number of receivers placed in the environment.</p>"},{"location":"API/Environments/base/#torchradio.env.base.BaseEnvironment.n_transmitters","title":"<code>n_transmitters: int</code>  <code>property</code>","text":"<p>Get current number of transmitters.</p> <p>Returns     The number of transmitters placed in the environment.</p>"},{"location":"API/Environments/base/#torchradio.env.base.BaseEnvironment.receivers","title":"<code>receivers: dict[str, Position]</code>  <code>property</code>","text":"<p>Get current receivers and their positions.</p> <p>Returns     A map from receiver names to positions</p>"},{"location":"API/Environments/base/#torchradio.env.base.BaseEnvironment.transmitters","title":"<code>transmitters: dict[str, Position]</code>  <code>property</code>","text":"<p>Get current transmitters and their positions.</p> <p>Returns     A map from transmitter names to positions</p>"},{"location":"API/Environments/base/#torchradio.env.base.BaseEnvironment.__init__","title":"<code>__init__(*, disable_differentiability_check=False)</code>","text":"<p>Create a clean environment that can be populated with devices.</p>"},{"location":"API/Environments/base/#torchradio.env.base.BaseEnvironment.is_differentiable","title":"<code>is_differentiable()</code>","text":"<p>Check the environment is differentiable.</p> <p>Gotcha: The differentiability check assumes that devices can be placed at Position(x=0, y=0, z=0). If this is impossible, you must either write your own differentiability check, or alter your environment to allow placements at the origin.</p> <p>Gotcha: As part of the differentiability check, the environment will be reset. If you have devices placed in the environment before calling this function, they will need to be re-placed afterwards.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the environment passes a basic differentiability test, where the output magnitude of a simple transmitter is driven to zero. If your environment is incorrectly classified as non-differentiable, please raise an issue at the repository issue tracker.</p> Example <pre><code>&gt;&gt;&gt; env = torchradio.env.null.NullEnvironment()\n&gt;&gt;&gt; env.is_differentiable()\nTrue\n</code></pre>"},{"location":"API/Environments/base/#torchradio.env.base.BaseEnvironment.place","title":"<code>place(transmitters, receivers)</code>","text":"<p>Place devices in the environment.</p> <p>Child classes must specify whether a device is in or out-of-bounds via the <code>_in_bounds</code> method. After the devices have been placed, <code>self._compute_propagation_parameters()</code> is called to determine simulation parameters. These simulation parameters do not need to be recomputed until the devices have been re-placed.</p> <p>Parameters:</p> Name Type Description Default <code>transmitters</code> <code>dict[str, Transmitter]</code> <p>Maps device names to <code>Transmitter</code>s.</p> required <code>receivers</code> <code>dict[str, Receiver]</code> <p>Maps device names to <code>Receivers</code>s.</p> required Example <pre><code>&gt;&gt;&gt; transmitter_1 = torchradio.algorithm.null.get_constant_transmitter(1 + 1j)\n&gt;&gt;&gt; transmitter_2 = torchradio.algorithm.null.get_constant_transmitter(1 + 0j)\n&gt;&gt;&gt; transmitter_3 = torchradio.algorithm.null.get_null_transmitter()\n&gt;&gt;&gt; receiver = torchradio.algorithm.null.get_null_receiver()\n&gt;&gt;&gt; some_transmitters = {\"tx1\": transmitter_1, \"tx2\": transmitter_2}\n&gt;&gt;&gt; other_transmitters = {\"tx3\": transmitter_3}\n&gt;&gt;&gt; all_transmitters = {**some_transmitters, **other_transmitters}\n&gt;&gt;&gt; receivers = {\"rx\": receiver}\n&gt;&gt;&gt; env = torchradio.env.null.NullEnvironment()\n&gt;&gt;&gt; env.place(some_transmitters, receivers)\n&gt;&gt;&gt; env.n_devices\n3\n&gt;&gt;&gt; env.place(all_transmitters, receivers)\n&gt;&gt;&gt; env.n_devices\n4\n</code></pre> <p>Raises:</p> Type Description <code>ValueError</code> <p>No receivers provided.</p> <code>TypeError</code> <p>A non-<code>Transmitter</code> was found in <code>transmitters</code> or a non-<code>Receiver</code> was found in <code>receivers</code>.</p>"},{"location":"API/Environments/base/#torchradio.env.base.BaseEnvironment.reset","title":"<code>reset()</code>","text":"<p>Remove all devices from the environment.</p> Example <pre><code>&gt;&gt;&gt; env.place(...)\n&gt;&gt;&gt; env.n_devices\n8\n&gt;&gt;&gt; env.reset()\n&gt;&gt;&gt; env.n_devices\n0\n</code></pre>"},{"location":"API/Environments/base/#torchradio.env.base.BaseEnvironment.simulate","title":"<code>simulate(n_timesteps, batch_size=1)</code>","text":"<p>Run the simulation for <code>n_timesteps</code> with <code>batch_size</code>.</p> <p>Parameters:</p> Name Type Description Default <code>n_timesteps</code> <code>int</code> <p>How many timesteps to simulate. Must be positive.</p> required <code>batch_size</code> <code>int</code> <p>How many batches to simulate. Must be positive.</p> <code>1</code> <p>Returns:</p> Type Description <code>DeviceLogs</code> <p>Device logs for benchmarking performance and computing gradients.</p> Example <pre><code>&gt;&gt;&gt; transmitter = torchradio.algorithm.null.get_null_transmitter()\n&gt;&gt;&gt; receiver = torchradio.algorithm.null.get_null_receiver()\n&gt;&gt;&gt; env = torchradio.env.null.NullEnvironment()\n&gt;&gt;&gt; env.place({\"tx\": transmitter}, {\"rx\": receiver})\n&gt;&gt;&gt; env.simulate(20, 3)\n</code></pre> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a provided <code>SpatialDistribution</code> is incompatible with the environment according to the child class <code>_in_bounds</code> methods.</p> <code>RuntimeError</code> <p>If child classes don't correctly implement <code>_propagate</code> or <code>_get_background_noise</code> to account for all devices.</p>"},{"location":"API/Environments/base/#torchradio.env.base.BaseEnvironment.visualize","title":"<code>visualize(*, show=True, save_path=None)</code>","text":"<p>Visualize the environment with the currently placed devices.</p> <p>It is not mandatory for child classes to override this method. However, it may make it easier for users to interact with the environment if they are provided with a convenient visualization method to see where devices are currently placed.</p> <p>Parameters:</p> Name Type Description Default <code>show</code> <code>bool</code> <p>Show an interactive plot within the Python process.</p> <code>True</code> <code>save_path</code> <code>PathLike | None</code> <p>Path to save the visualization to.</p> <code>None</code>"},{"location":"API/Environments/box/","title":"Box Environment","text":"<p>Simple box-like environments.</p>"},{"location":"API/Environments/box/#torchradio.env.box.Bounds3D","title":"<code>Bounds3D</code>  <code>dataclass</code>","text":"<p>A 3D region bounded by <code>[0, 0, 0]</code> and <code>[x_max, y_max, z_max]</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x_max</code> <code>float</code> <p>Bound x coordinates between 0 and <code>x_max</code>.</p> required <code>y_max</code> <code>float</code> <p>Bound y coordinates between 0 and <code>y_max</code>.</p> required <code>z_max</code> <code>float</code> <p>Bound z coordinates between 0 and <code>z_max</code>.</p> required Example <pre><code>&gt;&gt;&gt; bounds = Bounds3D(10, 10, 5)\n&gt;&gt;&gt; Position(9, 6, 4) in bounds\nTrue\n&gt;&gt;&gt; Position(9, 6, 6) in bounds\nFalse\n&gt;&gt;&gt; Position(9, -1, 4) in bounds\nFalse\n</code></pre>"},{"location":"API/Environments/box/#torchradio.env.box.Bounds3D.__contains__","title":"<code>__contains__(position)</code>","text":"<p>Determine if position is inside <code>Bounds3D</code>.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>Position</code> <p>Position to test.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the position is in bounds.</p>"},{"location":"API/Environments/box/#torchradio.env.box.BoxEnvironment","title":"<code>BoxEnvironment</code>","text":"<p>               Bases: <code>NullEnvironment</code></p> <p>A simple environment defined by a 3D region.</p>"},{"location":"API/Environments/box/#torchradio.env.box.BoxEnvironment.bounds","title":"<code>bounds: Bounds3D</code>  <code>property</code>","text":"<p>Public API for internal bounds.</p> <p>Returns     Three-dimensional bounds for the environment.</p>"},{"location":"API/Environments/box/#torchradio.env.box.BoxEnvironment.__init__","title":"<code>__init__(x_max, y_max, z_max)</code>","text":"<p>Create a new bounded <code>BoxEnvironment</code>.</p> <p>A <code>Position</code> is in bounds if <code>0 &lt;= x &lt;= x_max</code>, <code>0 &lt;= y &lt;= y_max</code> and <code>0 &lt;= z &lt;= z_max</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x_max</code> <code>float</code> <p>Maximum x coordinate</p> required <code>y_max</code> <code>float</code> <p>Maximum y coordinate</p> required <code>z_max</code> <code>float</code> <p>Maximum z coordinate</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>x_max &lt; 0</code> or <code>y_max &lt; 0</code> or <code>z_max &lt; 0</code>.</p>"},{"location":"API/Environments/box/#torchradio.env.box.BoxEnvironment.visualize","title":"<code>visualize(*, show=True, save_path=None)</code>","text":"<p>Visualize the environment with the currently placed devices.</p>"},{"location":"API/Environments/box/#torchradio.env.box.PlanarEnvironment","title":"<code>PlanarEnvironment</code>","text":"<p>               Bases: <code>BoxEnvironment</code></p> <p>A simple environment defined by a flat 2D region.</p> <p>Devices must have spatial distributions that place them at a height of z=0.</p>"},{"location":"API/Environments/box/#torchradio.env.box.PlanarEnvironment.__init__","title":"<code>__init__(x_max, y_max)</code>","text":"<p>Create a new bounded <code>PlanarEnvironment</code>.</p> <p>A <code>Position</code> is in bounds if <code>0 &lt;= x &lt;= x_max</code>, <code>0 &lt;= y &lt;= y_max</code> and <code>z == 0</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x_max</code> <code>float</code> <p>Maximum x coordinate</p> required <code>y_max</code> <code>float</code> <p>Maximum y coordinate</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>x_max &lt; 0</code> or <code>y_max &lt; 0</code>.</p>"},{"location":"API/Environments/box/#torchradio.env.box.PlanarEnvironment.visualize","title":"<code>visualize(*, show=True, save_path=None)</code>","text":"<p>Visualize the environment with the currently placed devices.</p>"},{"location":"API/Environments/null/","title":"Null Environments","text":"<p>Abstract environments that do not require physical device placements.</p>"},{"location":"API/Environments/null/#torchradio.env.null.ControlledSNREnvironment","title":"<code>ControlledSNREnvironment</code>","text":"<p>               Bases: <code>NullEnvironment</code></p> <p>A single-channel environment that applies additive white Gaussian noise (AWGN) to a specific signal-to-noise ratio (SNR).</p> <p>A null environment with controllable SNR that supports a single transmitter and receiver pair. During propagation, the transmitted signal is reduced to unit power. The correct amount of AWGN is then generated to achieve the specified SNR.</p> <p>Raises     ValueError: If more than one transmitter or more than one receiver.</p>"},{"location":"API/Environments/null/#torchradio.env.null.ControlledSNREnvironment.snr","title":"<code>snr: float</code>  <code>property</code>","text":"<p>Get the currently set signal-to-noise ratio in dB.</p> <p>Returns     Current signal-to-noise ratio in dB.</p>"},{"location":"API/Environments/null/#torchradio.env.null.ControlledSNREnvironment.__init__","title":"<code>__init__(snr)</code>","text":"<p>Create a <code>ControlledSNREnvironment</code> for single channel simulations with Gaussian noise.</p> <p>Parameters:</p> Name Type Description Default <code>snr</code> <code>float</code> <p>Desired signal-to-noise ratio in dB.</p> required"},{"location":"API/Environments/null/#torchradio.env.null.ControlledSNREnvironment.set_snr","title":"<code>set_snr(snr)</code>","text":"<p>Set signal-to-noise ratio (SNR) for the receiver in dB.</p> <p>Parameters:</p> Name Type Description Default <code>snr</code> <code>float</code> <p>Desired signal-to-noise ratio in dB.</p> required"},{"location":"API/Environments/null/#torchradio.env.null.NullEnvironment","title":"<code>NullEnvironment</code>","text":"<p>               Bases: <code>BaseEnvironment</code></p> <p>The simplest possible environment with ideal conditions.</p>"},{"location":"API/Environments/null/#torchradio.env.null.RandomAWGNEnvironment","title":"<code>RandomAWGNEnvironment</code>","text":"<p>               Bases: <code>NullEnvironment</code></p> <p>A null environment that produces a random level of background noise for each receiver.</p> <p>This random level is sampled per receiver according to the power bounds supplied at instantiation.</p>"},{"location":"API/Environments/null/#torchradio.env.null.RandomAWGNEnvironment.bounds","title":"<code>bounds: tuple[float, float]</code>  <code>property</code>","text":"<p>Get current noise bounds.</p> <p>Returns     Background noise bounds as a tuple.</p>"},{"location":"API/Environments/null/#torchradio.env.null.RandomAWGNEnvironment.__init__","title":"<code>__init__(p_min, p_max, *, normalize_before_noise=False)</code>","text":"<p>Initialize a new <code>RandomAWGNEnviroment</code> with bounded background noise levels.</p> <p>Parameters:</p> Name Type Description Default <code>p_min</code> <code>float</code> <p>Minimum background noise power.</p> required <code>p_max</code> <code>float</code> <p>Maximum background noise power.</p> required <code>normalize_before_noise</code> <code>bool</code> <p>Set to True if the aggregated signals should be normalized to unit power before adding background noise. Defaults to False.</p> <code>False</code>"},{"location":"API/Environments/null/#torchradio.env.null.RandomAWGNEnvironment.set_bounds","title":"<code>set_bounds(p_min, p_max)</code>","text":"<p>Set noise bounds for all receivers.</p> <p>Parameters:</p> Name Type Description Default <code>p_min</code> <code>float</code> <p>Minimum background noise power.</p> required <code>p_max</code> <code>float</code> <p>Maximum background noise power.</p> required"},{"location":"API/Environments/null/#torchradio.env.null.RandomBoundedSNREnvironment","title":"<code>RandomBoundedSNREnvironment</code>","text":"<p>               Bases: <code>ControlledSNREnvironment</code></p> <p>A single-channel environment that applies a random amount of additive white Gaussian noise (AWGN) according to preset SNR bounds.</p> <p>A null environment with bounded SNR that supports a single transmitter and receiver pair. During propagation, the transmitted signal is reduced to unit power. The correct amount of AWGN is then generated to achieve an SNR within the provided bounds.</p> <p>Raises     ValueError: If more than one transmitter or more than one receiver.</p>"},{"location":"API/Environments/null/#torchradio.env.null.RandomBoundedSNREnvironment.__init__","title":"<code>__init__(snr_min, snr_max)</code>","text":"<p>Create a <code>RandomBoundedSNREnvironment</code> for single channel simulations with Gaussian noise.</p> <p>Parameters:</p> Name Type Description Default <code>snr_min</code> <code>float</code> <p>Minimum desired signal-to-noise ratio in dB.</p> required <code>snr_max</code> <code>float</code> <p>Maximum desired signal-to-noise ratio in dB.</p> required Raise <p>ValueError: if <code>snr_max &lt; snr_min</code>.</p>"},{"location":"Examples/1_introduction/","title":"Introduction","text":"<p>Before running these notebooks, we recommend running:</p> <pre><code>pip install torchradio[notebooks]\n</code></pre> <p>to ensure you have all of the necessary dependencies.</p> In\u00a0[1]: Copied! <pre>from pprint import pformat, pprint\n\nfrom torchradio import Receiver, Transmitter\nfrom torchradio.algorithm import Modem\nfrom torchradio.env import PlanarEnvironment\nfrom torchradio.position import get_null_distribution, get_uniform_distribution\n</pre> from pprint import pformat, pprint  from torchradio import Receiver, Transmitter from torchradio.algorithm import Modem from torchradio.env import PlanarEnvironment from torchradio.position import get_null_distribution, get_uniform_distribution <p>Define an environment to simulate with dimensions 100 x 100. We will assume a planar environment. At initialization, there are no devices in the environment.</p> In\u00a0[2]: Copied! <pre>env = PlanarEnvironment(x_max=100, y_max=100)\nprint(f\"Bounds: {env.bounds}\")\nprint(f\"Devices: {pformat(env.devices)}\")\n</pre> env = PlanarEnvironment(x_max=100, y_max=100) print(f\"Bounds: {env.bounds}\") print(f\"Devices: {pformat(env.devices)}\") <pre>Bounds: Bounds3D(x_max=100, y_max=100, z_max=0)\nDevices: {'receivers': {}, 'transmitters': {}}\n</pre> <p>Let's define some devices for our environment. We will use the pre-built <code>Modem</code> class to make it easier to define devices. Each device needs to be specified with a so-called \"Spatial Distribution\". For each simulation, we will simulate the device's position according to this distribution.</p> <p>As an example, the next block defines a simple QPSK transmitter. The transmitter's position is sampled uniformly from a 10 x 20 metre rectangle located at (30, 40).</p> In\u00a0[3]: Copied! <pre>algorithm = Modem(\"psk\", 4).tx  # combine modem with Modem class and isolate the\nspatial_distribution = get_uniform_distribution([25, 35], [30, 50], [0, 0])\nqpsk_transmitter = Transmitter(algorithm, spatial_distribution)\nprint(qpsk_transmitter)\n</pre> algorithm = Modem(\"psk\", 4).tx  # combine modem with Modem class and isolate the spatial_distribution = get_uniform_distribution([25, 35], [30, 50], [0, 0]) qpsk_transmitter = Transmitter(algorithm, spatial_distribution) print(qpsk_transmitter) <pre>&lt;torchradio.device.Transmitter object at 0x7f6df4102c90&gt;\n</pre> <p>Note that a <code>Transmitter</code> can be defined with a <code>max_gain</code> parameter. Any transmissions that violate this gain will saturate the transmission.</p> <p>Calling <code>device.place()</code> will randomly sample a new position for the device according to its spatial distribution</p> In\u00a0[4]: Copied! <pre>for i in range(5):\n    print(f\"Placement {i}: {qpsk_transmitter.place()}\")\n</pre> for i in range(5):     print(f\"Placement {i}: {qpsk_transmitter.place()}\") <pre>Placement 0: Position(x=25.208818, y=38.12274, z=0.0)\nPlacement 1: Position(x=28.343914, y=41.070465, z=0.0)\nPlacement 2: Position(x=29.90762, y=47.56172, z=0.0)\nPlacement 3: Position(x=32.97873, y=42.237152, z=0.0)\nPlacement 4: Position(x=33.996162, y=39.393585, z=0.0)\n</pre> <p>We can use <code>get_null_distribution</code> if we want a device to be pinned to a single location.</p> In\u00a0[5]: Copied! <pre>spatial_distribution = get_null_distribution(30, 40)\nqpsk_transmitter = Transmitter(algorithm, spatial_distribution)\nfor i in range(5):\n    print(f\"Placement {i}: {qpsk_transmitter.place()}\")\n</pre> spatial_distribution = get_null_distribution(30, 40) qpsk_transmitter = Transmitter(algorithm, spatial_distribution) for i in range(5):     print(f\"Placement {i}: {qpsk_transmitter.place()}\") <pre>Placement 0: Position(x=30, y=40, z=0)\nPlacement 1: Position(x=30, y=40, z=0)\nPlacement 2: Position(x=30, y=40, z=0)\nPlacement 3: Position(x=30, y=40, z=0)\nPlacement 4: Position(x=30, y=40, z=0)\n</pre> <p>To create an interesting simulation environment with multiple transmitters and receivers, we first create dictionaries to house the device definitions. Note that the current use of <code>Modem</code> with overlapping centre frequencies and constellations will lead to incoherent receiver outputs. We will look at using more sensible algorithms later on.</p> In\u00a0[6]: Copied! <pre>transmitters = {\n    \"tx_1\": Transmitter(Modem(\"psk\", 4).tx, get_null_distribution(10, 10), 2),\n    \"tx_2\": Transmitter(Modem(\"psk\", 8).tx, get_null_distribution(20, 10), 3),\n    \"tx_3\": Transmitter(Modem(\"qam\", 4).tx, get_null_distribution(50, 80), 8),\n    \"tx_4\": Transmitter(Modem(\"psk\", 4).tx, get_null_distribution(20, 70)),\n}\n\nreceivers = {\n    \"rx_1\": Receiver(Modem(\"psk\", 4).rx, get_null_distribution(10, 10)),\n    \"rx_2\": Receiver(Modem(\"psk\", 8).rx, get_null_distribution(20, 10)),\n    \"rx_3\": Receiver(Modem(\"qam\", 4).rx, get_null_distribution(50, 80)),\n}\n\nprint(f\"Transmitters: {list(transmitters.keys())}\")\nprint(f\"Receivers: {list(receivers.keys())}\")\n</pre> transmitters = {     \"tx_1\": Transmitter(Modem(\"psk\", 4).tx, get_null_distribution(10, 10), 2),     \"tx_2\": Transmitter(Modem(\"psk\", 8).tx, get_null_distribution(20, 10), 3),     \"tx_3\": Transmitter(Modem(\"qam\", 4).tx, get_null_distribution(50, 80), 8),     \"tx_4\": Transmitter(Modem(\"psk\", 4).tx, get_null_distribution(20, 70)), }  receivers = {     \"rx_1\": Receiver(Modem(\"psk\", 4).rx, get_null_distribution(10, 10)),     \"rx_2\": Receiver(Modem(\"psk\", 8).rx, get_null_distribution(20, 10)),     \"rx_3\": Receiver(Modem(\"qam\", 4).rx, get_null_distribution(50, 80)), }  print(f\"Transmitters: {list(transmitters.keys())}\") print(f\"Receivers: {list(receivers.keys())}\") <pre>Transmitters: ['tx_1', 'tx_2', 'tx_3', 'tx_4']\nReceivers: ['rx_1', 'rx_2', 'rx_3']\n</pre> <p>We can now run place the devices in the environment. Notice the updated output from <code>env.devices</code>.</p> In\u00a0[7]: Copied! <pre>env.place(transmitters, receivers)\npprint(env.devices)\n</pre> env.place(transmitters, receivers) pprint(env.devices) <pre>{'receivers': {'rx_1': Position(x=10, y=10, z=0),\n               'rx_2': Position(x=20, y=10, z=0),\n               'rx_3': Position(x=50, y=80, z=0)},\n 'transmitters': {'tx_1': Position(x=10, y=10, z=0),\n                  'tx_2': Position(x=20, y=10, z=0),\n                  'tx_3': Position(x=50, y=80, z=0),\n                  'tx_4': Position(x=20, y=70, z=0)}}\n</pre> <p>We can remove devices from the environment by called <code>env.reset()</code></p> In\u00a0[8]: Copied! <pre>env.reset()\npprint(env.devices)\n</pre> env.reset() pprint(env.devices) <pre>{'receivers': {}, 'transmitters': {}}\n</pre> <p>Let's re-add the devices to the environment and run a simulation! <code>env.simulate</code> takes a single argument <code>n_timesteps</code> that determines how long the simulation will run for.</p> In\u00a0[9]: Copied! <pre>env.place(transmitters, receivers)\ndevice_logs = env.simulate(100)\n</pre> env.place(transmitters, receivers) device_logs = env.simulate(100) <p>The device logs can be used to compute losses and update trainable algorithms. These logs may also be used for analytical purposes to determine the performance characteristics of different algorithms.</p>"},{"location":"Examples/1_introduction/#introduction","title":"Introduction\u00b6","text":""},{"location":"Examples/2_benchmark_algorithms/","title":"Benchmark Algorithms","text":"<p>This notebook describes an approach for testing how well different tranmission and reception algorithms cope with varying levels of additive white Gaussian noise (AWGN).</p> <p>We begin with some imports.</p> In\u00a0[1]: Copied! <pre>from pprint import pprint\n\nimport pandas as pd\nimport plotly.express as px\nimport torch\nfrom IPython.display import Image\n\nfrom torchradio import DeviceLogs, Receiver, Transmitter\nfrom torchradio.algorithm import DSSS, Modem\nfrom torchradio.env.null import ControlledSNREnvironment\n</pre> from pprint import pprint  import pandas as pd import plotly.express as px import torch from IPython.display import Image  from torchradio import DeviceLogs, Receiver, Transmitter from torchradio.algorithm import DSSS, Modem from torchradio.env.null import ControlledSNREnvironment <p>Begin by defining a selection of algorithms to compare. Here, we use an assortment of different <code>Modem</code>-based algorithms.</p> In\u00a0[2]: Copied! <pre>modem_dict = {\n    \"BPSK\": Modem(\"psk\", 2),\n    \"QPSK\": Modem(\"psk\", 4),\n    \"PSK64\": Modem(\"psk\", 64),\n    \"QAM16\": Modem(\"qam\", 16),\n    \"DSSS-4-BPSK\": DSSS(torch.randint(0, 2, (4,))),\n    \"DSSS-8-BPSK\": DSSS(torch.randint(0, 2, (8,))),\n}\n\ntest_algorithms = {\n    modem_name: {\"tx\": Transmitter(modem.tx), \"rx\": Receiver(modem.rx)}\n    for modem_name, modem in modem_dict.items()\n}\n\ntransmitters, receivers = (\n    {\n        algorithm_name: algorithm[x]\n        for algorithm_name, algorithm in test_algorithms.items()\n    }\n    for x in [\"tx\", \"rx\"]\n)\n</pre> modem_dict = {     \"BPSK\": Modem(\"psk\", 2),     \"QPSK\": Modem(\"psk\", 4),     \"PSK64\": Modem(\"psk\", 64),     \"QAM16\": Modem(\"qam\", 16),     \"DSSS-4-BPSK\": DSSS(torch.randint(0, 2, (4,))),     \"DSSS-8-BPSK\": DSSS(torch.randint(0, 2, (8,))), }  test_algorithms = {     modem_name: {\"tx\": Transmitter(modem.tx), \"rx\": Receiver(modem.rx)}     for modem_name, modem in modem_dict.items() }  transmitters, receivers = (     {         algorithm_name: algorithm[x]         for algorithm_name, algorithm in test_algorithms.items()     }     for x in [\"tx\", \"rx\"] ) <p>Next, we create a special environment called <code>ControlledSNREnvironment</code>. This environment supports a single transmitter/receiver pair at a time, and applies AWGN according to same pre-specified signal-to-noise ratio (SNR). <code>ControlledSNREnvironment</code> is an unbounded environment that does not take device positions into account.</p> <p>Let's begin with an SNR of 0. That is, the power of the signal is equal to the power of the background noise.</p> In\u00a0[3]: Copied! <pre>env = ControlledSNREnvironment(0)\n</pre> env = ControlledSNREnvironment(0) <p>We can place a single QPSK transmitter/receiver inside a <code>ControlledSNREnvironment</code> at a time like so.</p> In\u00a0[4]: Copied! <pre>transmitter_name = \"tx-test\"\nreceiver_name = \"rx-test\"\nalgorithm = \"QPSK\"\nenv.place(\n    {transmitter_name: transmitters[algorithm]},\n    {receiver_name: receivers[algorithm]},\n)\npprint(env.devices)\n</pre> transmitter_name = \"tx-test\" receiver_name = \"rx-test\" algorithm = \"QPSK\" env.place(     {transmitter_name: transmitters[algorithm]},     {receiver_name: receivers[algorithm]}, ) pprint(env.devices) <pre>{'receivers': {'rx-test': Position(x=0, y=0, z=0)},\n 'transmitters': {'tx-test': Position(x=0, y=0, z=0)}}\n</pre> <p>If we attempt to place too many devices, <code>ControlledSNREnvironment</code> will raise a <code>ValueError</code>.</p> <pre>&gt;&gt;&gt; env.place(\n&gt;&gt;&gt;     {transmitter_name: transmitters[algorithm], \"tx-test2\": transmitters[\"bpsk\"]},\n&gt;&gt;&gt;     {receiver_name: receivers[algorithm]}\n&gt;&gt;&gt; )\nValueError(...)\n</pre> <p>Let's revert to the previous device placement and run a simulation for 200 timesteps.</p> In\u00a0[5]: Copied! <pre>env.place(\n    {transmitter_name: transmitters[algorithm]},\n    {receiver_name: receivers[algorithm]},\n)\ndevice_logs = env.simulate(200)\n</pre> env.place(     {transmitter_name: transmitters[algorithm]},     {receiver_name: receivers[algorithm]}, ) device_logs = env.simulate(200) <p>From <code>device_logs</code> we can carry out an analysis.</p> In\u00a0[6]: Copied! <pre>def _analyze(device_logs: DeviceLogs, *, verbose: bool = False) -&gt; dict[str, float]:\n    # get transmitter and receiver names\n    transmitter_names = list(device_logs.tx.keys())\n    receiver_names = list(device_logs.rx.keys())\n\n    # check device_logs only contain a single tx/rx pair\n    assert len(transmitter_names) == 1\n    assert len(receiver_names) == 1\n\n    transmitter_name = transmitter_names[0]\n    receiver_name = receiver_names[0]\n\n    # transmitted and received bits\n    original_bits = device_logs.tx[transmitter_name].metadata[\"bits\"]\n    recovered_bits = device_logs.rx[receiver_name][\"bits\"]\n    matched_bits = recovered_bits == original_bits\n    bit_error_rate = 1 - torch.mean(matched_bits.float()).item()\n\n    # separate received signal and noise\n    background_noise = device_logs.rx[receiver_name][\"noise\"]\n    rx_pure_signal = device_logs.rx[receiver_name][\"raw\"] - background_noise\n    snr = (\n        10 * torch.log10(torch.var(rx_pure_signal) / torch.var(background_noise)).item()\n    )\n\n    # throughput\n    n_bits = original_bits.shape[-1]\n    signal_length = device_logs.tx[transmitter_name].signal.shape[-1]\n    throughput = n_bits / signal_length\n\n    if verbose:\n        print(f\"Basic Analysis for {transmitter_name} to {receiver_name}:\")\n        print(f\"- Bit Error Rate: {100 * bit_error_rate:.2f}%\")\n        print(f\"- SNR: {snr:.2f}dB\")\n        print(f\"- Throughput: {throughput} bits per sample\")\n\n    return {\"Bit Error Rate\": bit_error_rate, \"SNR (dB)\": snr, \"Throughput\": throughput}\n\n\nanalysis = _analyze(device_logs, verbose=True)\n</pre> def _analyze(device_logs: DeviceLogs, *, verbose: bool = False) -&gt; dict[str, float]:     # get transmitter and receiver names     transmitter_names = list(device_logs.tx.keys())     receiver_names = list(device_logs.rx.keys())      # check device_logs only contain a single tx/rx pair     assert len(transmitter_names) == 1     assert len(receiver_names) == 1      transmitter_name = transmitter_names[0]     receiver_name = receiver_names[0]      # transmitted and received bits     original_bits = device_logs.tx[transmitter_name].metadata[\"bits\"]     recovered_bits = device_logs.rx[receiver_name][\"bits\"]     matched_bits = recovered_bits == original_bits     bit_error_rate = 1 - torch.mean(matched_bits.float()).item()      # separate received signal and noise     background_noise = device_logs.rx[receiver_name][\"noise\"]     rx_pure_signal = device_logs.rx[receiver_name][\"raw\"] - background_noise     snr = (         10 * torch.log10(torch.var(rx_pure_signal) / torch.var(background_noise)).item()     )      # throughput     n_bits = original_bits.shape[-1]     signal_length = device_logs.tx[transmitter_name].signal.shape[-1]     throughput = n_bits / signal_length      if verbose:         print(f\"Basic Analysis for {transmitter_name} to {receiver_name}:\")         print(f\"- Bit Error Rate: {100 * bit_error_rate:.2f}%\")         print(f\"- SNR: {snr:.2f}dB\")         print(f\"- Throughput: {throughput} bits per sample\")      return {\"Bit Error Rate\": bit_error_rate, \"SNR (dB)\": snr, \"Throughput\": throughput}   analysis = _analyze(device_logs, verbose=True) <pre>Basic Analysis for tx-test to rx-test:\n- Bit Error Rate: 14.25%\n- SNR: 0.00dB\n- Throughput: 2.0 bits per sample\n</pre> <p>We can carry out the same analysis over many different algorithms and SNRs like so:</p> In\u00a0[7]: Copied! <pre>results_dict = {\"Algorithm\": []}\nn_timesteps = 5120\nfor snr in torch.linspace(-15, 5, 40):\n    env.set_snr(snr)\n    for algorithm_name, devices in test_algorithms.items():\n        env.place(\n            {f\"{algorithm_name}-tx\": devices[\"tx\"]},\n            {f\"{algorithm_name}-rx\": devices[\"rx\"]},\n        )\n        device_logs = env.simulate(n_timesteps)\n        result = _analyze(device_logs, verbose=False)\n\n        results_dict[\"Algorithm\"].append(algorithm_name)\n\n        for k, v in result.items():\n            if k not in results_dict:\n                results_dict[k] = []\n            results_dict[k].append(v)\n</pre> results_dict = {\"Algorithm\": []} n_timesteps = 5120 for snr in torch.linspace(-15, 5, 40):     env.set_snr(snr)     for algorithm_name, devices in test_algorithms.items():         env.place(             {f\"{algorithm_name}-tx\": devices[\"tx\"]},             {f\"{algorithm_name}-rx\": devices[\"rx\"]},         )         device_logs = env.simulate(n_timesteps)         result = _analyze(device_logs, verbose=False)          results_dict[\"Algorithm\"].append(algorithm_name)          for k, v in result.items():             if k not in results_dict:                 results_dict[k] = []             results_dict[k].append(v) <p>Converting the <code>results</code> dictionary into a <code>pd.DataFrame</code> yields:</p> In\u00a0[8]: Copied! <pre>results_df = pd.DataFrame(results_dict)\nresults_df.head()\n</pre> results_df = pd.DataFrame(results_dict) results_df.head() Out[8]: Algorithm Bit Error Rate SNR (dB) Throughput 0 BPSK 0.404883 -14.999999 1.00 1 QPSK 0.428320 -15.000000 2.00 2 PSK64 0.478190 -15.000000 6.00 3 QAM16 0.471094 -15.000000 4.00 4 DSSS-4-BPSK 0.340625 -14.999999 0.25 <p>From a <code>pd.DataFrame</code> we can easily create figures using tools such as <code>plotly</code>.</p> In\u00a0[9]: Copied! <pre>fig = px.line(\n    results_df,\n    x=\"SNR (dB)\",\n    y=\"Bit Error Rate\",\n    color=\"Algorithm\",\n    title=\"Bit Error Rate vs SNR\",\n    log_y=True,\n)\nImage(fig.to_image(format=\"png\"))\n</pre> fig = px.line(     results_df,     x=\"SNR (dB)\",     y=\"Bit Error Rate\",     color=\"Algorithm\",     title=\"Bit Error Rate vs SNR\",     log_y=True, ) Image(fig.to_image(format=\"png\")) Out[9]: In\u00a0[10]: Copied! <pre>throughput_df = results_df.groupby(\"Algorithm\")[\"Throughput\"].mean().reset_index()\nfig = px.bar(\n    throughput_df,\n    x=\"Algorithm\",\n    y=\"Throughput\",\n    log_y=False,\n    title=\"Bit Error Rate vs SNR\",\n)\nImage(fig.to_image(format=\"png\"))\n</pre> throughput_df = results_df.groupby(\"Algorithm\")[\"Throughput\"].mean().reset_index() fig = px.bar(     throughput_df,     x=\"Algorithm\",     y=\"Throughput\",     log_y=False,     title=\"Bit Error Rate vs SNR\", ) Image(fig.to_image(format=\"png\")) Out[10]: <p>We can examine algorithms for performance tradeoffs between bit error rate and throughput at -10dB. Examining such tradeoffs is important when we want to determine whether an AI-discovered algorithm has any edge over state-of-the-art.</p> In\u00a0[11]: Copied! <pre>def _normalize_column(df: pd.DataFrame, column_name: str) -&gt; None:\n    df[f\"Normalized {column_name}\"] = df[column_name] / df[column_name].abs().max()\n\n\n# isolate low SNR results\nsnr_limit = -14.9\nlow_snr_results = results_df[results_df[\"SNR (dB)\"] &lt; snr_limit].copy()\n\n# \"explode\" each row with tradeoff parameter alpha\nlow_snr_results[\"alpha\"] = [\n    torch.linspace(0, 1, 20).numpy().tolist() for _ in range(len(low_snr_results.index))\n]\nlow_snr_results = low_snr_results.explode(\"alpha\").reset_index()\n\n# normalize columns to make scales for tradeoff metrics similar\n_normalize_column(low_snr_results, \"Throughput\")\n_normalize_column(low_snr_results, \"Bit Error Rate\")\n\n# compute scores\nlow_snr_results[\"Score\"] = low_snr_results.apply(\n    lambda x: (1 - x[\"alpha\"]) * (1 / x[\"Normalized Bit Error Rate\"])\n    + x[\"alpha\"] * x[\"Normalized Throughput\"],\n    axis=1,\n)\n_normalize_column(low_snr_results, \"Score\")\n\nfig = px.line(\n    low_snr_results,\n    x=\"alpha\",\n    y=\"Normalized Score\",\n    color=\"Algorithm\",\n    title=\"Tradeoff Curve for Bit Error Rate at -10dB vs. Throughput\",\n    labels={\"alpha\": \"Throughput Priority\"},\n)\nImage(fig.to_image(format=\"png\"))\n</pre> def _normalize_column(df: pd.DataFrame, column_name: str) -&gt; None:     df[f\"Normalized {column_name}\"] = df[column_name] / df[column_name].abs().max()   # isolate low SNR results snr_limit = -14.9 low_snr_results = results_df[results_df[\"SNR (dB)\"] &lt; snr_limit].copy()  # \"explode\" each row with tradeoff parameter alpha low_snr_results[\"alpha\"] = [     torch.linspace(0, 1, 20).numpy().tolist() for _ in range(len(low_snr_results.index)) ] low_snr_results = low_snr_results.explode(\"alpha\").reset_index()  # normalize columns to make scales for tradeoff metrics similar _normalize_column(low_snr_results, \"Throughput\") _normalize_column(low_snr_results, \"Bit Error Rate\")  # compute scores low_snr_results[\"Score\"] = low_snr_results.apply(     lambda x: (1 - x[\"alpha\"]) * (1 / x[\"Normalized Bit Error Rate\"])     + x[\"alpha\"] * x[\"Normalized Throughput\"],     axis=1, ) _normalize_column(low_snr_results, \"Score\")  fig = px.line(     low_snr_results,     x=\"alpha\",     y=\"Normalized Score\",     color=\"Algorithm\",     title=\"Tradeoff Curve for Bit Error Rate at -10dB vs. Throughput\",     labels={\"alpha\": \"Throughput Priority\"}, ) Image(fig.to_image(format=\"png\")) Out[11]:"},{"location":"Examples/2_benchmark_algorithms/#benchmark-algorithms","title":"Benchmark Algorithms\u00b6","text":""},{"location":"Examples/3_train_detector/","title":"Train a Basic Detector","text":"<p>In this example, we will use <code>torchradio</code> to train a detector. A detector is a simple binary classifier that reports the probability that a given family of transmitters are active. Note that detection does not fully capture <code>torchradio</code>'s core feature of backpropagation to tranmission. However, this is still a useful example to see how we can train a single aspect of a communications channel.</p> <p>We start by defining some common imports.</p> In\u00a0[1]: Copied! <pre>from random import randint\n\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport torch\nfrom IPython.display import Image\nfrom torch import nn\nfrom tqdm import tqdm\n\nfrom torchradio import Receiver, Reception, Transmitter\nfrom torchradio.algorithm import Modem\nfrom torchradio.env.null import RandomAWGNEnvironment\n</pre> from random import randint  import numpy as np import pandas as pd import plotly.express as px import torch from IPython.display import Image from torch import nn from tqdm import tqdm  from torchradio import Receiver, Reception, Transmitter from torchradio.algorithm import Modem from torchradio.env.null import RandomAWGNEnvironment <p>For this experiment, we define two transmitters and a detector. One transmitter will be our transmitter-of-interest, and the other is just a source of background noise.</p> In\u00a0[2]: Copied! <pre>transmitters = {\n    \"target\": Transmitter(Modem(\"psk\", 4).tx),\n    \"ignore\": Transmitter(Modem(\"qam\", 16).tx),\n}\n</pre> transmitters = {     \"target\": Transmitter(Modem(\"psk\", 4).tx),     \"ignore\": Transmitter(Modem(\"qam\", 16).tx), } <p>Let's define a trainable detection algorithm called <code>QPSKDetector</code>.</p> In\u00a0[3]: Copied! <pre>class QPSKDetector(nn.Module):\n    \"\"\"A trainable detector that uses convolutional layers to detect QPSK.\"\"\"\n\n    def __init__(self) -&gt; None:  # noqa: D107\n        super().__init__()\n\n        self._conv = nn.Sequential(\n            nn.LazyConv1d(16, 16, 5),\n            nn.ReLU(),\n            nn.LazyConv1d(32, 8, 3),\n            nn.ReLU(),\n            nn.LazyConv1d(64, 4, 1),\n            nn.ReLU(),\n        )\n\n        self._ff = nn.Sequential(\n            nn.LazyLinear(64),\n            nn.ReLU(),\n            nn.Dropout(p=0.1),\n            nn.LazyLinear(1),\n            nn.Sigmoid(),\n        )\n\n        self._flatten = nn.Flatten()\n\n    def rx(self, signal: torch.Tensor) -&gt; Reception:  # noqa: D102\n        return {\"probabilities\": self.forward(signal)}\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:  # noqa: D102\n        x = torch.stack([x.real, x.imag]).transpose(1, 0)\n        x = self._flatten(self._conv(x))\n        return self._ff(x)\n</pre> class QPSKDetector(nn.Module):     \"\"\"A trainable detector that uses convolutional layers to detect QPSK.\"\"\"      def __init__(self) -&gt; None:  # noqa: D107         super().__init__()          self._conv = nn.Sequential(             nn.LazyConv1d(16, 16, 5),             nn.ReLU(),             nn.LazyConv1d(32, 8, 3),             nn.ReLU(),             nn.LazyConv1d(64, 4, 1),             nn.ReLU(),         )          self._ff = nn.Sequential(             nn.LazyLinear(64),             nn.ReLU(),             nn.Dropout(p=0.1),             nn.LazyLinear(1),             nn.Sigmoid(),         )          self._flatten = nn.Flatten()      def rx(self, signal: torch.Tensor) -&gt; Reception:  # noqa: D102         return {\"probabilities\": self.forward(signal)}      def forward(self, x: torch.Tensor) -&gt; torch.Tensor:  # noqa: D102         x = torch.stack([x.real, x.imag]).transpose(1, 0)         x = self._flatten(self._conv(x))         return self._ff(x) <p>Let's now instantiate <code>QPSKDetector</code> and add it to a receiver. Notice that we only provide the <code>rx</code> method to the <code>Receiver</code> class. The simulation only needs to know about the forward pass.</p> In\u00a0[4]: Copied! <pre>detection_algorithm = QPSKDetector()\nreceivers = {\"detector\": Receiver(detection_algorithm.rx)}\n</pre> detection_algorithm = QPSKDetector() receivers = {\"detector\": Receiver(detection_algorithm.rx)} <pre>/home/daniel/code/torchradio/venv/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n  warnings.warn('Lazy modules are a new feature under heavy development '\n</pre> <p>We will use a predefined <code>torchradio</code> environment called <code>RandomAWGNEnvironment</code>. For each receiver, the transmissions will be randomly attenuated and a random amount of AWGN will be applied. The amount of AWGN per run is sampled uniformly from the bounds specified at initialization.</p> In\u00a0[5]: Copied! <pre>env = RandomAWGNEnvironment(0, 1)\n</pre> env = RandomAWGNEnvironment(0, 1) <p>We define a helper function <code>get_subset</code> to random select a subset of the available transmitters.</p> In\u00a0[6]: Copied! <pre>def get_subset() -&gt; dict[str, Transmitter]:\n    \"\"\"Get a random subset of the transmitters.\"\"\"\n    subset = {}\n    for transmitter_name, transmitter in transmitters.items():\n        if randint(0, 1) == 0:  # noqa: S311\n            subset[transmitter_name] = transmitter  # noqa: PERF403\n    return subset\n</pre> def get_subset() -&gt; dict[str, Transmitter]:     \"\"\"Get a random subset of the transmitters.\"\"\"     subset = {}     for transmitter_name, transmitter in transmitters.items():         if randint(0, 1) == 0:  # noqa: S311             subset[transmitter_name] = transmitter  # noqa: PERF403     return subset <p>Next we define function called <code>train</code>. At each iteration, iterate over all possible transmitter subsets (including the empty set). We then penalize the receiver depending on how well it classifies the presence of the target transmitter.</p> In\u00a0[7]: Copied! <pre>loss_fn = nn.BCELoss()\noptimizer = torch.optim.Adam(detection_algorithm.parameters(), lr=1e-4)\n\n# manually specify all possible subsets\nplacements = [\n    {},\n    {\"target\": transmitters[\"target\"]},\n    {\"ignore\": transmitters[\"ignore\"]},\n    transmitters,\n]\n\n\ndef _train(\n    n_timesteps: int,\n    batch_size: int,\n    threshold: float = 0.5,\n) -&gt; dict[str, float]:\n    optimizer.zero_grad()\n\n    accuracies = []\n    for p in placements:\n        env.place(p, receivers)\n\n        device_logs = env.simulate(n_timesteps, batch_size)\n        detector_output = device_logs.rx[\"detector\"][\"probabilities\"]\n\n        # compute loss, gradient and update parameters\n        label = (\n            torch.ones_like(detector_output)\n            if \"target\" in p\n            else torch.zeros_like(detector_output)\n        )\n        loss = loss_fn(detector_output, label)\n        loss.backward()  # accumulate over different subsets\n\n        # bookkeeping\n        accuracies.append(\n            torch.mean(((detector_output &gt; threshold) == label.bool()).float()).numpy(),\n        )\n\n    optimizer.step()\n\n    return {\"loss\": loss.detach().numpy(), \"accuracy\": np.mean(accuracies)}\n</pre> loss_fn = nn.BCELoss() optimizer = torch.optim.Adam(detection_algorithm.parameters(), lr=1e-4)  # manually specify all possible subsets placements = [     {},     {\"target\": transmitters[\"target\"]},     {\"ignore\": transmitters[\"ignore\"]},     transmitters, ]   def _train(     n_timesteps: int,     batch_size: int,     threshold: float = 0.5, ) -&gt; dict[str, float]:     optimizer.zero_grad()      accuracies = []     for p in placements:         env.place(p, receivers)          device_logs = env.simulate(n_timesteps, batch_size)         detector_output = device_logs.rx[\"detector\"][\"probabilities\"]          # compute loss, gradient and update parameters         label = (             torch.ones_like(detector_output)             if \"target\" in p             else torch.zeros_like(detector_output)         )         loss = loss_fn(detector_output, label)         loss.backward()  # accumulate over different subsets          # bookkeeping         accuracies.append(             torch.mean(((detector_output &gt; threshold) == label.bool()).float()).numpy(),         )      optimizer.step()      return {\"loss\": loss.detach().numpy(), \"accuracy\": np.mean(accuracies)} <p>We can now call <code>_train</code> multiple times to train our detector.</p> In\u00a0[8]: Copied! <pre># track metrics over time\nlosses = []\naccuracies = []\n\nn_iterations = 1000\nbatch_size = 10\nn_timesteps = 128\n\nfor _ in tqdm(range(n_iterations)):\n    train_logs = _train(n_timesteps, batch_size)\n    losses.append(train_logs[\"loss\"])\n    accuracies.append(train_logs[\"accuracy\"])\n</pre> # track metrics over time losses = [] accuracies = []  n_iterations = 1000 batch_size = 10 n_timesteps = 128  for _ in tqdm(range(n_iterations)):     train_logs = _train(n_timesteps, batch_size)     losses.append(train_logs[\"loss\"])     accuracies.append(train_logs[\"accuracy\"]) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [01:27&lt;00:00, 11.44it/s]\n</pre> <p>We can plot the losses to observe improvement over time.</p> In\u00a0[9]: Copied! <pre>fig = px.line(\n    pd.DataFrame({\"loss\": losses, \"iteration\": list(range(len(losses)))}),\n    x=\"iteration\",\n    y=\"loss\",\n    log_y=False,\n    title=\"Detection Loss\",\n    labels={\"iteration\": \"Iteration\", \"loss\": \"Loss\"},\n)\nImage(fig.to_image(format=\"png\"))\n</pre> fig = px.line(     pd.DataFrame({\"loss\": losses, \"iteration\": list(range(len(losses)))}),     x=\"iteration\",     y=\"loss\",     log_y=False,     title=\"Detection Loss\",     labels={\"iteration\": \"Iteration\", \"loss\": \"Loss\"}, ) Image(fig.to_image(format=\"png\")) Out[9]: In\u00a0[10]: Copied! <pre>fig = px.line(\n    pd.DataFrame({\"accuracy\": accuracies, \"iteration\": list(range(len(accuracies)))}),\n    x=\"iteration\",\n    y=\"accuracy\",\n    title=\"Detection Accuracy\",\n    labels={\"iteration\": \"Iteration\", \"accuracy\": \"Accuracy\"},\n)\nImage(fig.to_image(format=\"png\"))\n</pre> fig = px.line(     pd.DataFrame({\"accuracy\": accuracies, \"iteration\": list(range(len(accuracies)))}),     x=\"iteration\",     y=\"accuracy\",     title=\"Detection Accuracy\",     labels={\"iteration\": \"Iteration\", \"accuracy\": \"Accuracy\"}, ) Image(fig.to_image(format=\"png\")) Out[10]:"},{"location":"Examples/3_train_detector/#train-a-basic-detector","title":"Train a Basic Detector\u00b6","text":""},{"location":"Examples/4_train_basic_comms/","title":"Train Basic Communications","text":"<p>Let us train a one-way communication system from scratch. First, let's import the necessary components.</p> In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport torch\nfrom IPython.display import Image\nfrom torch import nn\nfrom tqdm import tqdm\n\nfrom torchradio import Receiver, Transmitter\nfrom torchradio.algorithm.example import DenseRadio\nfrom torchradio.env.null import RandomAWGNEnvironment\n</pre> import numpy as np import pandas as pd import plotly.express as px import torch from IPython.display import Image from torch import nn from tqdm import tqdm  from torchradio import Receiver, Transmitter from torchradio.algorithm.example import DenseRadio from torchradio.env.null import RandomAWGNEnvironment <p>We will use a predefined trainable <code>DenseRadio</code> from the <code>torchradio.algorithm.example</code> module. As its name suggests, a <code>DenseRadio</code> uses so-called \"dense\" layers) to encode and decode messages. The <code>DenseRadio</code> is not especially configurable, but is good enough for the purposes of this notebook. Feel free to study the <code>DenseRadio</code> implementation to help you design your own trainable radios.</p> <p>We instantiate the radio and define a similar environment to that described in train_detector.ipynb.</p> In\u00a0[2]: Copied! <pre>dense_radio = DenseRadio(8, 2)\ntransmitters = {\"dense_tx\": Transmitter(dense_radio.tx)}\nreceivers = {\"dense_rx\": Receiver(dense_radio.rx)}\nenv = RandomAWGNEnvironment(0, 1.0)\nenv.place(transmitters, receivers)\n</pre> dense_radio = DenseRadio(8, 2) transmitters = {\"dense_tx\": Transmitter(dense_radio.tx)} receivers = {\"dense_rx\": Receiver(dense_radio.rx)} env = RandomAWGNEnvironment(0, 1.0) env.place(transmitters, receivers) <p>Next, define a training loop that penalises bit errors.</p> In\u00a0[3]: Copied! <pre>loss_fn = nn.BCELoss()\noptimizer = torch.optim.Adam(dense_radio.parameters(), lr=5e-4)\n\n\ndef _train(\n    n_timesteps: int,\n    batch_size: int,\n) -&gt; dict[str, float]:\n    optimizer.zero_grad()\n\n    device_logs = env.simulate(n_timesteps, batch_size)\n\n    tx_bits = device_logs.tx[\"dense_tx\"].metadata[\"bits\"]\n    rx_outputs = device_logs.rx[\"dense_rx\"][\"bit_probabilities\"]\n    rx_bits = device_logs.rx[\"dense_rx\"][\"bits\"]\n\n    # compute loss, gradient and update parameters\n    loss = loss_fn(rx_outputs, tx_bits.float())\n    loss.backward()\n    optimizer.step()\n\n    return {\n        \"loss\": loss.detach().numpy(),\n        \"accuracy\": np.mean((tx_bits == rx_bits).numpy()),\n    }\n</pre> loss_fn = nn.BCELoss() optimizer = torch.optim.Adam(dense_radio.parameters(), lr=5e-4)   def _train(     n_timesteps: int,     batch_size: int, ) -&gt; dict[str, float]:     optimizer.zero_grad()      device_logs = env.simulate(n_timesteps, batch_size)      tx_bits = device_logs.tx[\"dense_tx\"].metadata[\"bits\"]     rx_outputs = device_logs.rx[\"dense_rx\"][\"bit_probabilities\"]     rx_bits = device_logs.rx[\"dense_rx\"][\"bits\"]      # compute loss, gradient and update parameters     loss = loss_fn(rx_outputs, tx_bits.float())     loss.backward()     optimizer.step()      return {         \"loss\": loss.detach().numpy(),         \"accuracy\": np.mean((tx_bits == rx_bits).numpy()),     } <p>We can now call <code>_train</code> multiple times to train our radio.</p> In\u00a0[4]: Copied! <pre># track metrics over time\nlosses = []\nbit_error_rates = []\n\nn_iterations = 2000\nbatch_size = 10\nn_timesteps = 64\n\nfor _ in tqdm(range(n_iterations)):\n    train_logs = _train(n_timesteps, batch_size)\n    losses.append(train_logs[\"loss\"])\n    bit_error_rates.append(1 - train_logs[\"accuracy\"])\n</pre> # track metrics over time losses = [] bit_error_rates = []  n_iterations = 2000 batch_size = 10 n_timesteps = 64  for _ in tqdm(range(n_iterations)):     train_logs = _train(n_timesteps, batch_size)     losses.append(train_logs[\"loss\"])     bit_error_rates.append(1 - train_logs[\"accuracy\"]) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2000/2000 [00:01&lt;00:00, 1045.30it/s]\n</pre> <p>We can plot the loss per iteration.</p> In\u00a0[5]: Copied! <pre>fig = px.line(\n    pd.DataFrame({\"loss\": losses, \"iteration\": list(range(len(losses)))}),\n    x=\"iteration\",\n    y=\"loss\",\n    log_y=True,\n    title=\"Communications Loss\",\n    labels={\"iteration\": \"Iteration\", \"loss\": \"Loss\"},\n)\nImage(fig.to_image(format=\"png\"))\n</pre> fig = px.line(     pd.DataFrame({\"loss\": losses, \"iteration\": list(range(len(losses)))}),     x=\"iteration\",     y=\"loss\",     log_y=True,     title=\"Communications Loss\",     labels={\"iteration\": \"Iteration\", \"loss\": \"Loss\"}, ) Image(fig.to_image(format=\"png\")) Out[5]: <p>We can also plot the bit-error-rate per iteration.</p> In\u00a0[6]: Copied! <pre>fig = px.line(\n    pd.DataFrame(\n        {\n            \"bit_error_rates\": bit_error_rates,\n            \"iteration\": list(range(len(bit_error_rates))),\n        },\n    ),\n    x=\"iteration\",\n    y=\"bit_error_rates\",\n    log_y=False,\n    title=\"Bit Error Rate\",\n    labels={\"iteration\": \"Iteration\", \"bit_error_rates\": \"Bit Error Rate\"},\n)\nImage(fig.to_image(format=\"png\"))\n</pre> fig = px.line(     pd.DataFrame(         {             \"bit_error_rates\": bit_error_rates,             \"iteration\": list(range(len(bit_error_rates))),         },     ),     x=\"iteration\",     y=\"bit_error_rates\",     log_y=False,     title=\"Bit Error Rate\",     labels={\"iteration\": \"Iteration\", \"bit_error_rates\": \"Bit Error Rate\"}, ) Image(fig.to_image(format=\"png\")) Out[6]:"},{"location":"Examples/4_train_basic_comms/#train-basic-communications","title":"Train Basic Communications\u00b6","text":""},{"location":"Examples/5_train_novel_comms/","title":"Train Novel Communications","text":"<p>The Train Basic Communications notebook demonstrated how we could build a simple one-way communication system using <code>torchradio</code>. Since we are free to define whatever objective function we like, we train radios for more interesting mulitple-input multiple-output scenarios.</p> <p>Let us begin by defining some common building blocks.</p> In\u00a0[1]: Copied! <pre>import functools\nimport operator\n\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport torch\nfrom IPython.display import Image\nfrom torch import nn\nfrom tqdm import tqdm\n\nfrom torchradio import Receiver, Transmitter\nfrom torchradio.algorithm.example import (\n    DenseReceptionAlgorithm,\n    DenseTransmissionAlgorithm,\n)\nfrom torchradio.algorithm.utils import get_all_parameters\nfrom torchradio.env.null import RandomAWGNEnvironment\n</pre> import functools import operator  import numpy as np import pandas as pd import plotly.express as px import torch from IPython.display import Image from torch import nn from tqdm import tqdm  from torchradio import Receiver, Transmitter from torchradio.algorithm.example import (     DenseReceptionAlgorithm,     DenseTransmissionAlgorithm, ) from torchradio.algorithm.utils import get_all_parameters from torchradio.env.null import RandomAWGNEnvironment <p>For each scenario, we use the same environment as Train Basic Communications. Each scenario will contain multiple radios composed of <code>DenseTransmissionAlgorithm</code>s and <code>DenseReceptionAlgorithm</code>s.</p> In\u00a0[2]: Copied! <pre>env = RandomAWGNEnvironment(0, 1.0)\n</pre> env = RandomAWGNEnvironment(0, 1.0) In\u00a0[3]: Copied! <pre>n_bits_per_channel = 8\ntransmitters = {\n    \"tx\": Transmitter(DenseTransmissionAlgorithm(2 * n_bits_per_channel, 4)),\n}\nreceivers = {\n    k: Receiver(DenseReceptionAlgorithm(n_bits_per_channel, 64)) for k in [\"rx1\", \"rx2\"]\n}\nenv.place(transmitters, receivers)\n</pre> n_bits_per_channel = 8 transmitters = {     \"tx\": Transmitter(DenseTransmissionAlgorithm(2 * n_bits_per_channel, 4)), } receivers = {     k: Receiver(DenseReceptionAlgorithm(n_bits_per_channel, 64)) for k in [\"rx1\", \"rx2\"] } env.place(transmitters, receivers) <p>Next, define a training loop. We divide <code>device_logs.tx[\"tx\"].metadata[\"bits\"]</code> down the middle, with the first half intended for <code>\"rx1\"</code> and the second half for <code>\"rx2\"</code>.</p> In\u00a0[4]: Copied! <pre>loss_fn = nn.BCELoss()\noptimizer = torch.optim.Adam(\n    get_all_parameters(list(transmitters.values()), list(receivers.values())),\n    lr=5e-4,\n)\n\n\ndef _train(\n    n_timesteps: int,\n    batch_size: int,\n) -&gt; dict[str, float]:\n    optimizer.zero_grad()\n\n    device_logs = env.simulate(n_timesteps, batch_size)\n\n    tx_bits = device_logs.tx[\"tx\"].metadata[\"bits\"]\n    rx_outputs = {k: v[\"bit_probabilities\"] for k, v in device_logs.rx.items()}\n    rx_bits = {k: v[\"bits\"] for k, v in device_logs.rx.items()}\n\n    # compute loss, gradient and update parameters\n    rx1_loss = loss_fn(rx_outputs[\"rx1\"], tx_bits.float()[:, :n_bits_per_channel])\n    rx2_loss = loss_fn(rx_outputs[\"rx2\"], tx_bits.float()[:, n_bits_per_channel:])\n    loss = rx1_loss + rx2_loss\n    loss.backward()\n    optimizer.step()\n\n    return {\n        \"rx1_loss\": float(rx1_loss.detach().numpy()),\n        \"rx2_loss\": float(rx2_loss.detach().numpy()),\n        \"rx1_accuracy\": float(\n            np.mean((tx_bits[:, :n_bits_per_channel] == rx_bits[\"rx1\"]).numpy()),\n        ),\n        \"rx2_accuracy\": float(\n            np.mean((tx_bits[:, n_bits_per_channel:] == rx_bits[\"rx2\"]).numpy()),\n        ),\n    }\n</pre> loss_fn = nn.BCELoss() optimizer = torch.optim.Adam(     get_all_parameters(list(transmitters.values()), list(receivers.values())),     lr=5e-4, )   def _train(     n_timesteps: int,     batch_size: int, ) -&gt; dict[str, float]:     optimizer.zero_grad()      device_logs = env.simulate(n_timesteps, batch_size)      tx_bits = device_logs.tx[\"tx\"].metadata[\"bits\"]     rx_outputs = {k: v[\"bit_probabilities\"] for k, v in device_logs.rx.items()}     rx_bits = {k: v[\"bits\"] for k, v in device_logs.rx.items()}      # compute loss, gradient and update parameters     rx1_loss = loss_fn(rx_outputs[\"rx1\"], tx_bits.float()[:, :n_bits_per_channel])     rx2_loss = loss_fn(rx_outputs[\"rx2\"], tx_bits.float()[:, n_bits_per_channel:])     loss = rx1_loss + rx2_loss     loss.backward()     optimizer.step()      return {         \"rx1_loss\": float(rx1_loss.detach().numpy()),         \"rx2_loss\": float(rx2_loss.detach().numpy()),         \"rx1_accuracy\": float(             np.mean((tx_bits[:, :n_bits_per_channel] == rx_bits[\"rx1\"]).numpy()),         ),         \"rx2_accuracy\": float(             np.mean((tx_bits[:, n_bits_per_channel:] == rx_bits[\"rx2\"]).numpy()),         ),     } In\u00a0[5]: Copied! <pre># track metrics over time\nrx1_losses = []\nrx2_losses = []\nrx1_bit_error_rates = []\nrx2_bit_error_rates = []\n\nn_iterations = 2000\nbatch_size = 10\nn_timesteps = 64\n\nfor _ in tqdm(range(n_iterations)):\n    train_logs = _train(n_timesteps, batch_size)\n\n    rx1_losses.append(train_logs[\"rx1_loss\"])\n    rx2_losses.append(train_logs[\"rx2_loss\"])\n    rx1_bit_error_rates.append(1 - train_logs[\"rx1_accuracy\"])\n    rx2_bit_error_rates.append(1 - train_logs[\"rx2_accuracy\"])\n</pre> # track metrics over time rx1_losses = [] rx2_losses = [] rx1_bit_error_rates = [] rx2_bit_error_rates = []  n_iterations = 2000 batch_size = 10 n_timesteps = 64  for _ in tqdm(range(n_iterations)):     train_logs = _train(n_timesteps, batch_size)      rx1_losses.append(train_logs[\"rx1_loss\"])     rx2_losses.append(train_logs[\"rx2_loss\"])     rx1_bit_error_rates.append(1 - train_logs[\"rx1_accuracy\"])     rx2_bit_error_rates.append(1 - train_logs[\"rx2_accuracy\"]) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2000/2000 [00:02&lt;00:00, 740.45it/s]\n</pre> In\u00a0[6]: Copied! <pre>losses = [*rx1_losses, *rx2_losses]\niterations = [*list(range(n_iterations)), *list(range(n_iterations))]\nreceiver_names = [\"rx1\" for _ in range(n_iterations)] + [\n    \"rx2\" for _ in range(n_iterations)\n]\n\nfig = px.line(\n    pd.DataFrame({\"Receiver\": receiver_names, \"Iteration\": iterations, \"Loss\": losses}),\n    x=\"Iteration\",\n    y=\"Loss\",\n    color=\"Receiver\",\n    log_y=True,\n    title=\"Single Transmitter Dual Receiver Loss\",\n)\nImage(fig.to_image(format=\"png\"))\n</pre> losses = [*rx1_losses, *rx2_losses] iterations = [*list(range(n_iterations)), *list(range(n_iterations))] receiver_names = [\"rx1\" for _ in range(n_iterations)] + [     \"rx2\" for _ in range(n_iterations) ]  fig = px.line(     pd.DataFrame({\"Receiver\": receiver_names, \"Iteration\": iterations, \"Loss\": losses}),     x=\"Iteration\",     y=\"Loss\",     color=\"Receiver\",     log_y=True,     title=\"Single Transmitter Dual Receiver Loss\", ) Image(fig.to_image(format=\"png\")) Out[6]: In\u00a0[7]: Copied! <pre>bit_error_rates = [*rx1_bit_error_rates, *rx2_bit_error_rates]\n\nfig = px.line(\n    pd.DataFrame(\n        {\n            \"Receiver\": receiver_names,\n            \"Iteration\": iterations,\n            \"Bit Error Rate\": bit_error_rates,\n        },\n    ),\n    x=\"Iteration\",\n    y=\"Bit Error Rate\",\n    color=\"Receiver\",\n    log_y=False,\n    title=\"Single Transmitter Dual Receiver Bit Error Rate\",\n)\nImage(fig.to_image(format=\"png\"))\n</pre> bit_error_rates = [*rx1_bit_error_rates, *rx2_bit_error_rates]  fig = px.line(     pd.DataFrame(         {             \"Receiver\": receiver_names,             \"Iteration\": iterations,             \"Bit Error Rate\": bit_error_rates,         },     ),     x=\"Iteration\",     y=\"Bit Error Rate\",     color=\"Receiver\",     log_y=False,     title=\"Single Transmitter Dual Receiver Bit Error Rate\", ) Image(fig.to_image(format=\"png\")) Out[7]: In\u00a0[8]: Copied! <pre>n_bits_per_channel = 8\ntransmitters = {\n    k: Transmitter(DenseTransmissionAlgorithm(n_bits_per_channel, 4))\n    for k in [\"tx1\", \"tx2\"]\n}\nreceivers = {\"rx\": Receiver(DenseReceptionAlgorithm(2 * n_bits_per_channel, 32))}\nenv.place(transmitters, receivers)\n</pre> n_bits_per_channel = 8 transmitters = {     k: Transmitter(DenseTransmissionAlgorithm(n_bits_per_channel, 4))     for k in [\"tx1\", \"tx2\"] } receivers = {\"rx\": Receiver(DenseReceptionAlgorithm(2 * n_bits_per_channel, 32))} env.place(transmitters, receivers) <p>We define a similar training loop to before. This time, we divide <code>device_logs.rx[\"rx\"][\"bits\"]</code> down the middle, with the first half intended for <code>\"tx1\"</code> and the second half for <code>\"tx2\"</code>.</p> In\u00a0[9]: Copied! <pre>loss_fn = nn.BCELoss()\noptimizer = torch.optim.Adam(\n    get_all_parameters(list(transmitters.values()), list(receivers.values())),\n    lr=5e-4,\n)\n\n\ndef _train(\n    n_timesteps: int,\n    batch_size: int,\n) -&gt; dict[str, float]:\n    optimizer.zero_grad()\n\n    device_logs = env.simulate(n_timesteps, batch_size)\n\n    tx_bits = {k: v.metadata[\"bits\"] for k, v in device_logs.tx.items()}\n    rx_outputs = device_logs.rx[\"rx\"][\"bit_probabilities\"]\n    rx_bits = device_logs.rx[\"rx\"][\"bits\"]\n\n    # compute loss, gradient and update parameters\n    tx1_loss = loss_fn(rx_outputs[:, :n_bits_per_channel], tx_bits[\"tx1\"].float())\n    tx2_loss = loss_fn(rx_outputs[:, n_bits_per_channel:], tx_bits[\"tx2\"].float())\n    loss = tx1_loss + tx2_loss\n    loss.backward()\n    optimizer.step()\n\n    return {\n        \"tx1_loss\": float(tx1_loss.detach().numpy()),\n        \"tx2_loss\": float(tx2_loss.detach().numpy()),\n        \"tx1_accuracy\": float(\n            np.mean((tx_bits[\"tx1\"] == rx_bits[:, :n_bits_per_channel]).numpy()),\n        ),\n        \"tx2_accuracy\": float(\n            np.mean((tx_bits[\"tx2\"] == rx_bits[:, n_bits_per_channel:]).numpy()),\n        ),\n    }\n</pre> loss_fn = nn.BCELoss() optimizer = torch.optim.Adam(     get_all_parameters(list(transmitters.values()), list(receivers.values())),     lr=5e-4, )   def _train(     n_timesteps: int,     batch_size: int, ) -&gt; dict[str, float]:     optimizer.zero_grad()      device_logs = env.simulate(n_timesteps, batch_size)      tx_bits = {k: v.metadata[\"bits\"] for k, v in device_logs.tx.items()}     rx_outputs = device_logs.rx[\"rx\"][\"bit_probabilities\"]     rx_bits = device_logs.rx[\"rx\"][\"bits\"]      # compute loss, gradient and update parameters     tx1_loss = loss_fn(rx_outputs[:, :n_bits_per_channel], tx_bits[\"tx1\"].float())     tx2_loss = loss_fn(rx_outputs[:, n_bits_per_channel:], tx_bits[\"tx2\"].float())     loss = tx1_loss + tx2_loss     loss.backward()     optimizer.step()      return {         \"tx1_loss\": float(tx1_loss.detach().numpy()),         \"tx2_loss\": float(tx2_loss.detach().numpy()),         \"tx1_accuracy\": float(             np.mean((tx_bits[\"tx1\"] == rx_bits[:, :n_bits_per_channel]).numpy()),         ),         \"tx2_accuracy\": float(             np.mean((tx_bits[\"tx2\"] == rx_bits[:, n_bits_per_channel:]).numpy()),         ),     } <p>Train!</p> In\u00a0[10]: Copied! <pre># track metrics over time\ntx1_losses = []\ntx2_losses = []\ntx1_bit_error_rates = []\ntx2_bit_error_rates = []\n\nn_iterations = 3000\nbatch_size = 20\nn_timesteps = 32\n\nfor _ in tqdm(range(n_iterations)):\n    train_logs = _train(n_timesteps, batch_size)\n\n    tx1_losses.append(train_logs[\"tx1_loss\"])\n    tx2_losses.append(train_logs[\"tx2_loss\"])\n    tx1_bit_error_rates.append(1 - train_logs[\"tx1_accuracy\"])\n    tx2_bit_error_rates.append(1 - train_logs[\"tx2_accuracy\"])\n</pre> # track metrics over time tx1_losses = [] tx2_losses = [] tx1_bit_error_rates = [] tx2_bit_error_rates = []  n_iterations = 3000 batch_size = 20 n_timesteps = 32  for _ in tqdm(range(n_iterations)):     train_logs = _train(n_timesteps, batch_size)      tx1_losses.append(train_logs[\"tx1_loss\"])     tx2_losses.append(train_logs[\"tx2_loss\"])     tx1_bit_error_rates.append(1 - train_logs[\"tx1_accuracy\"])     tx2_bit_error_rates.append(1 - train_logs[\"tx2_accuracy\"]) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3000/3000 [00:04&lt;00:00, 747.66it/s]\n</pre> <p>We can plot the losses for each transmitter.</p> In\u00a0[11]: Copied! <pre>losses = [*tx1_losses, *tx2_losses]\niterations = [*list(range(n_iterations)), *list(range(n_iterations))]\ntransmitter_names = [\"tx1\" for _ in range(n_iterations)] + [\n    \"tx2\" for _ in range(n_iterations)\n]\n\nfig = px.line(\n    pd.DataFrame(\n        {\"Transmitter\": transmitter_names, \"Iteration\": iterations, \"Loss\": losses},\n    ),\n    x=\"Iteration\",\n    y=\"Loss\",\n    color=\"Transmitter\",\n    log_y=True,\n    title=\"Dual Transmitter Single Receiver Loss\",\n)\nImage(fig.to_image(format=\"png\"))\n</pre> losses = [*tx1_losses, *tx2_losses] iterations = [*list(range(n_iterations)), *list(range(n_iterations))] transmitter_names = [\"tx1\" for _ in range(n_iterations)] + [     \"tx2\" for _ in range(n_iterations) ]  fig = px.line(     pd.DataFrame(         {\"Transmitter\": transmitter_names, \"Iteration\": iterations, \"Loss\": losses},     ),     x=\"Iteration\",     y=\"Loss\",     color=\"Transmitter\",     log_y=True,     title=\"Dual Transmitter Single Receiver Loss\", ) Image(fig.to_image(format=\"png\")) Out[11]: <p>As well as the bit error rates...</p> In\u00a0[12]: Copied! <pre>bit_error_rates = [*tx1_bit_error_rates, *tx2_bit_error_rates]\n\nfig = px.line(\n    pd.DataFrame(\n        {\n            \"Transmitter\": transmitter_names,\n            \"Iteration\": iterations,\n            \"Bit Error Rate\": bit_error_rates,\n        },\n    ),\n    x=\"Iteration\",\n    y=\"Bit Error Rate\",\n    color=\"Transmitter\",\n    log_y=False,\n    title=\"Dual Transmitter Single Receiver Bit Error Rate\",\n)\nImage(fig.to_image(format=\"png\"))\n</pre> bit_error_rates = [*tx1_bit_error_rates, *tx2_bit_error_rates]  fig = px.line(     pd.DataFrame(         {             \"Transmitter\": transmitter_names,             \"Iteration\": iterations,             \"Bit Error Rate\": bit_error_rates,         },     ),     x=\"Iteration\",     y=\"Bit Error Rate\",     color=\"Transmitter\",     log_y=False,     title=\"Dual Transmitter Single Receiver Bit Error Rate\", ) Image(fig.to_image(format=\"png\")) Out[12]: <p>Interestingly, these experiments indicate that it is harder to receive two simultaneous signals than it is to transmit two simultaneous signals.</p> <p>Finally, we look at a scenario where multiple radios need to share the same band. We will define three <code>DenseRadio</code>s and train them to share the spectrum with one another.</p> In\u00a0[13]: Copied! <pre>n_radios = 3\ntransmitters = {\n    f\"tx{i}\": Transmitter(DenseTransmissionAlgorithm(16, 4)) for i in range(n_radios)\n}\nreceivers = {\n    f\"rx{i}\": Receiver(DenseReceptionAlgorithm(16, 64)) for i in range(n_radios)\n}\nenv.place(transmitters, receivers)\n</pre> n_radios = 3 transmitters = {     f\"tx{i}\": Transmitter(DenseTransmissionAlgorithm(16, 4)) for i in range(n_radios) } receivers = {     f\"rx{i}\": Receiver(DenseReceptionAlgorithm(16, 64)) for i in range(n_radios) } env.place(transmitters, receivers) In\u00a0[14]: Copied! <pre>loss_fn = nn.BCELoss()\noptimizer = torch.optim.Adam(\n    get_all_parameters(list(transmitters.values()), list(receivers.values())),\n    lr=5e-4,\n)\n\n\ndef _train(\n    n_timesteps: int,\n    batch_size: int,\n) -&gt; dict[str, float]:\n    optimizer.zero_grad()\n\n    device_logs = env.simulate(n_timesteps, batch_size)\n\n    tx_bits = {k: v.metadata[\"bits\"] for k, v in device_logs.tx.items()}\n    rx_outputs = {k: v[\"bit_probabilities\"] for k, v in device_logs.rx.items()}\n    rx_bits = {k: v[\"bits\"] for k, v in device_logs.rx.items()}\n\n    # compute loss, gradient and update parameters\n    losses = [\n        loss_fn(rx_outputs[f\"rx{i}\"], tx_bits[f\"tx{i}\"].float())\n        for i in range(n_radios)\n    ]\n    loss = sum(losses)\n    loss.backward()\n    optimizer.step()\n\n    accuracies = [\n        float(np.mean((tx_bits[f\"tx{i}\"] == rx_bits[f\"rx{i}\"]).numpy()))\n        for i in range(n_radios)\n    ]\n\n    return {\n        \"losses\": [float(l_.detach().numpy()) for l_ in losses],\n        \"accuracies\": accuracies,\n    }\n</pre> loss_fn = nn.BCELoss() optimizer = torch.optim.Adam(     get_all_parameters(list(transmitters.values()), list(receivers.values())),     lr=5e-4, )   def _train(     n_timesteps: int,     batch_size: int, ) -&gt; dict[str, float]:     optimizer.zero_grad()      device_logs = env.simulate(n_timesteps, batch_size)      tx_bits = {k: v.metadata[\"bits\"] for k, v in device_logs.tx.items()}     rx_outputs = {k: v[\"bit_probabilities\"] for k, v in device_logs.rx.items()}     rx_bits = {k: v[\"bits\"] for k, v in device_logs.rx.items()}      # compute loss, gradient and update parameters     losses = [         loss_fn(rx_outputs[f\"rx{i}\"], tx_bits[f\"tx{i}\"].float())         for i in range(n_radios)     ]     loss = sum(losses)     loss.backward()     optimizer.step()      accuracies = [         float(np.mean((tx_bits[f\"tx{i}\"] == rx_bits[f\"rx{i}\"]).numpy()))         for i in range(n_radios)     ]      return {         \"losses\": [float(l_.detach().numpy()) for l_ in losses],         \"accuracies\": accuracies,     } In\u00a0[15]: Copied! <pre># track metrics over time\nlosses = []\naccuracies = []\n\nn_iterations = 4000\nbatch_size = 10\nn_timesteps = 64\n\nfor _ in tqdm(range(n_iterations)):\n    train_logs = _train(n_timesteps, batch_size)\n    losses.append(train_logs[\"losses\"])\n    accuracies.append(train_logs[\"accuracies\"])\n</pre> # track metrics over time losses = [] accuracies = []  n_iterations = 4000 batch_size = 10 n_timesteps = 64  for _ in tqdm(range(n_iterations)):     train_logs = _train(n_timesteps, batch_size)     losses.append(train_logs[\"losses\"])     accuracies.append(train_logs[\"accuracies\"]) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4000/4000 [00:09&lt;00:00, 421.15it/s]\n</pre> In\u00a0[16]: Copied! <pre>results = pd.DataFrame(\n    {\n        \"Channel\": functools.reduce(\n            operator.iadd, [list(range(n_radios)) for _ in range(n_iterations)], []\n        ),\n        \"Iteration\": functools.reduce(\n            operator.iadd,\n            [[i for _ in range(n_radios)] for i in range(n_iterations)],\n            [],\n        ),\n        \"Loss\": functools.reduce(operator.iadd, losses, []),\n        \"Bit Error Rate\": 1\n        - torch.tensor(functools.reduce(operator.iadd, accuracies, [])),\n    },\n)\n\nfig = px.line(\n    results,\n    x=\"Iteration\",\n    y=\"Loss\",\n    color=\"Channel\",\n    log_y=True,\n    title=\"Channel Loss\",\n)\nImage(fig.to_image(format=\"png\"))\n</pre> results = pd.DataFrame(     {         \"Channel\": functools.reduce(             operator.iadd, [list(range(n_radios)) for _ in range(n_iterations)], []         ),         \"Iteration\": functools.reduce(             operator.iadd,             [[i for _ in range(n_radios)] for i in range(n_iterations)],             [],         ),         \"Loss\": functools.reduce(operator.iadd, losses, []),         \"Bit Error Rate\": 1         - torch.tensor(functools.reduce(operator.iadd, accuracies, [])),     }, )  fig = px.line(     results,     x=\"Iteration\",     y=\"Loss\",     color=\"Channel\",     log_y=True,     title=\"Channel Loss\", ) Image(fig.to_image(format=\"png\")) Out[16]: In\u00a0[17]: Copied! <pre>fig = px.line(\n    results,\n    x=\"Iteration\",\n    y=\"Bit Error Rate\",\n    color=\"Channel\",\n    log_y=False,\n    title=\"Channel Bit Error Rate\",\n)\nImage(fig.to_image(format=\"png\"))\n</pre> fig = px.line(     results,     x=\"Iteration\",     y=\"Bit Error Rate\",     color=\"Channel\",     log_y=False,     title=\"Channel Bit Error Rate\", ) Image(fig.to_image(format=\"png\")) Out[17]:"},{"location":"Examples/5_train_novel_comms/#train-novel-communications","title":"Train Novel Communications\u00b6","text":""},{"location":"Examples/5_train_novel_comms/#single-transmitter-dual-receiver","title":"Single Transmitter Dual Receiver\u00b6","text":"<p>We first envisage a scenario with a one transmitter and two receivers. The transmitter must send a different mesage to each receiver.</p>"},{"location":"Examples/5_train_novel_comms/#dual-transmitter-single-receiver","title":"Dual Transmitter Single Receiver\u00b6","text":"<p>Next, we envisage a scenario with two transmitters and one receivers. The receiver must successfully decode the messages being received from both transmitters. We follow similar steps from before.</p>"},{"location":"Examples/5_train_novel_comms/#channel-sharing","title":"Channel Sharing\u00b6","text":""},{"location":"Examples/6_compare_novel_vs_conventional/","title":"Compare Novel and Conventional Radios","text":"<p>This notebook looks at how we can compare a trained radio with a conventional radio. In this case we compare our <code>DenseRadio</code> with DSSS-BPSK.</p> <p>We begin as always with our imports.</p> In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport torch\nfrom IPython.display import Image\nfrom torch import nn\nfrom tqdm import tqdm\n\nfrom torchradio import DeviceLogs, Receiver, Transmitter\nfrom torchradio.algorithm import DSSS\nfrom torchradio.algorithm.example import DenseRadio\nfrom torchradio.env.null import ControlledSNREnvironment, RandomBoundedSNREnvironment\n</pre> import numpy as np import pandas as pd import plotly.express as px import torch from IPython.display import Image from torch import nn from tqdm import tqdm  from torchradio import DeviceLogs, Receiver, Transmitter from torchradio.algorithm import DSSS from torchradio.algorithm.example import DenseRadio from torchradio.env.null import ControlledSNREnvironment, RandomBoundedSNREnvironment <p>Let's add some seeds for reproducibility.</p> In\u00a0[2]: Copied! <pre>seed = 0\ntorch.manual_seed(seed)\nnp.random.seed(seed)  # noqa: NPY002\n</pre> seed = 0 torch.manual_seed(seed) np.random.seed(seed)  # noqa: NPY002 <p>Let's define a radio similar to the one from Train Basic Communications. In this case we select the arguments <code>(8, 13)</code> so that it has the same throughout as the DSSS-BPSK algorithm that we will define later.</p> <p>We use a new environment here called <code>RandomBoundedSNREnvironment</code>, which will select random SNRs between -10 and +10dB for each simulation.</p> In\u00a0[3]: Copied! <pre>dense_radio = DenseRadio(\n    8,\n    13,\n)  # to have same throughput as DSSS-BPSK with Barker code 13\ntransmitters = {\"dense_tx\": Transmitter(dense_radio.tx)}\nreceivers = {\"dense_rx\": Receiver(dense_radio.rx)}\ntrain_env = RandomBoundedSNREnvironment(-20, 0)\ntrain_env.place(transmitters, receivers)\n</pre> dense_radio = DenseRadio(     8,     13, )  # to have same throughput as DSSS-BPSK with Barker code 13 transmitters = {\"dense_tx\": Transmitter(dense_radio.tx)} receivers = {\"dense_rx\": Receiver(dense_radio.rx)} train_env = RandomBoundedSNREnvironment(-20, 0) train_env.place(transmitters, receivers) <p>We train the radio like before...</p> In\u00a0[4]: Copied! <pre>loss_fn = nn.BCELoss()\noptimizer = torch.optim.Adam(dense_radio.parameters(), lr=1e-4)\nn_iterations = 20_000\nbatch_size = 10\nn_timesteps = 128\nlosses = []\n\n\ndef _train(\n    n_timesteps: int,\n    batch_size: int,\n) -&gt; dict[str, float]:\n    optimizer.zero_grad()\n\n    device_logs = train_env.simulate(n_timesteps, batch_size)\n\n    tx_bits = device_logs.tx[\"dense_tx\"].metadata[\"bits\"]\n    rx_outputs = device_logs.rx[\"dense_rx\"][\"bit_probabilities\"]\n    rx_bits = device_logs.rx[\"dense_rx\"][\"bits\"]\n\n    # compute loss, gradient and update parameters\n    loss = loss_fn(rx_outputs, tx_bits.float())\n    loss.backward()\n    optimizer.step()\n\n    return {\n        \"loss\": loss.detach().numpy(),\n        \"accuracy\": np.mean((tx_bits == rx_bits).numpy()),\n    }\n\n\nfor _ in tqdm(range(n_iterations)):\n    train_logs = _train(n_timesteps, batch_size)\n    losses.append(train_logs[\"loss\"])\n</pre> loss_fn = nn.BCELoss() optimizer = torch.optim.Adam(dense_radio.parameters(), lr=1e-4) n_iterations = 20_000 batch_size = 10 n_timesteps = 128 losses = []   def _train(     n_timesteps: int,     batch_size: int, ) -&gt; dict[str, float]:     optimizer.zero_grad()      device_logs = train_env.simulate(n_timesteps, batch_size)      tx_bits = device_logs.tx[\"dense_tx\"].metadata[\"bits\"]     rx_outputs = device_logs.rx[\"dense_rx\"][\"bit_probabilities\"]     rx_bits = device_logs.rx[\"dense_rx\"][\"bits\"]      # compute loss, gradient and update parameters     loss = loss_fn(rx_outputs, tx_bits.float())     loss.backward()     optimizer.step()      return {         \"loss\": loss.detach().numpy(),         \"accuracy\": np.mean((tx_bits == rx_bits).numpy()),     }   for _ in tqdm(range(n_iterations)):     train_logs = _train(n_timesteps, batch_size)     losses.append(train_logs[\"loss\"]) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20000/20000 [00:23&lt;00:00, 842.38it/s]\n</pre> <p>And visualize the losses over time to observe training performance. Notice the use of a moving average filter to smooth out the noise.</p> In\u00a0[5]: Copied! <pre>smoothing_interval = 200\ntraining_df = pd.DataFrame(\n    {\n        \"loss\": np.convolve(\n            losses,\n            np.ones((smoothing_interval,)) / smoothing_interval,\n            mode=\"valid\",\n        ),\n        \"iteration\": list(range(len(losses[: -(smoothing_interval - 1)]))),\n    },\n)\nfig = px.line(\n    training_df,\n    x=\"iteration\",\n    y=\"loss\",\n    log_y=True,\n    title=\"Communications Loss\",\n    labels={\"iteration\": \"Iteration\", \"loss\": \"Loss\"},\n)\nImage(fig.to_image(format=\"png\"))\n</pre> smoothing_interval = 200 training_df = pd.DataFrame(     {         \"loss\": np.convolve(             losses,             np.ones((smoothing_interval,)) / smoothing_interval,             mode=\"valid\",         ),         \"iteration\": list(range(len(losses[: -(smoothing_interval - 1)]))),     }, ) fig = px.line(     training_df,     x=\"iteration\",     y=\"loss\",     log_y=True,     title=\"Communications Loss\",     labels={\"iteration\": \"Iteration\", \"loss\": \"Loss\"}, ) Image(fig.to_image(format=\"png\")) Out[5]: <p>Let's now define the algorithms under test, following a similar procedure to Benchmark Algorithms.</p> <p>We compare <code>DenseRadio</code> with a BPSK-DSSS algorithm that uses the optimal Barker-13 chip sequence.</p> In\u00a0[6]: Copied! <pre>barker_13 = torch.tensor([1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1])\nmodem = DSSS(barker_13)\n\ntest_algorithms = {\n    \"DSSS-BPSK\": {\"tx\": Transmitter(modem.tx), \"rx\": Receiver(modem.rx)},\n    \"DenseRadio\": {\"tx\": Transmitter(dense_radio.tx), \"rx\": Receiver(dense_radio.rx)},\n}\n\ntransmitters, receivers = (\n    {\n        algorithm_name: algorithm[x]\n        for algorithm_name, algorithm in test_algorithms.items()\n    }\n    for x in [\"tx\", \"rx\"]\n)\n</pre> barker_13 = torch.tensor([1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1]) modem = DSSS(barker_13)  test_algorithms = {     \"DSSS-BPSK\": {\"tx\": Transmitter(modem.tx), \"rx\": Receiver(modem.rx)},     \"DenseRadio\": {\"tx\": Transmitter(dense_radio.tx), \"rx\": Receiver(dense_radio.rx)}, }  transmitters, receivers = (     {         algorithm_name: algorithm[x]         for algorithm_name, algorithm in test_algorithms.items()     }     for x in [\"tx\", \"rx\"] ) In\u00a0[7]: Copied! <pre>def _analyze(device_logs: DeviceLogs, *, verbose: bool = False) -&gt; dict[str, float]:\n    # get transmitter and receiver names\n    transmitter_names = list(device_logs.tx.keys())\n    receiver_names = list(device_logs.rx.keys())\n\n    # check device_logs only contain a single tx/rx pair\n    assert len(transmitter_names) == 1\n    assert len(receiver_names) == 1\n\n    transmitter_name = transmitter_names[0]\n    receiver_name = receiver_names[0]\n\n    # transmitted and received bits\n    original_bits = device_logs.tx[transmitter_name].metadata[\"bits\"]\n    recovered_bits = device_logs.rx[receiver_name][\"bits\"]\n    matched_bits = recovered_bits == original_bits\n    bit_error_rate = 1 - torch.mean(matched_bits.float()).item()\n\n    # separate received signal and noise\n    background_noise = device_logs.rx[receiver_name][\"noise\"]\n    rx_pure_signal = device_logs.rx[receiver_name][\"raw\"] - background_noise\n    snr = (\n        10 * torch.log10(torch.var(rx_pure_signal) / torch.var(background_noise)).item()\n    )\n\n    # throughput\n    n_bits = original_bits.shape[-1]\n    signal_length = device_logs.tx[transmitter_name].signal.shape[-1]\n    throughput = n_bits / signal_length\n\n    if verbose:\n        print(f\"Basic Analysis for {transmitter_name} to {receiver_name}:\")\n        print(f\"- Bit Error Rate: {100 * bit_error_rate:.2f}%\")\n        print(f\"- SNR: {snr:.2f}dB\")\n\n    return {\"Bit Error Rate\": bit_error_rate, \"SNR (dB)\": snr, \"Throughput\": throughput}\n</pre> def _analyze(device_logs: DeviceLogs, *, verbose: bool = False) -&gt; dict[str, float]:     # get transmitter and receiver names     transmitter_names = list(device_logs.tx.keys())     receiver_names = list(device_logs.rx.keys())      # check device_logs only contain a single tx/rx pair     assert len(transmitter_names) == 1     assert len(receiver_names) == 1      transmitter_name = transmitter_names[0]     receiver_name = receiver_names[0]      # transmitted and received bits     original_bits = device_logs.tx[transmitter_name].metadata[\"bits\"]     recovered_bits = device_logs.rx[receiver_name][\"bits\"]     matched_bits = recovered_bits == original_bits     bit_error_rate = 1 - torch.mean(matched_bits.float()).item()      # separate received signal and noise     background_noise = device_logs.rx[receiver_name][\"noise\"]     rx_pure_signal = device_logs.rx[receiver_name][\"raw\"] - background_noise     snr = (         10 * torch.log10(torch.var(rx_pure_signal) / torch.var(background_noise)).item()     )      # throughput     n_bits = original_bits.shape[-1]     signal_length = device_logs.tx[transmitter_name].signal.shape[-1]     throughput = n_bits / signal_length      if verbose:         print(f\"Basic Analysis for {transmitter_name} to {receiver_name}:\")         print(f\"- Bit Error Rate: {100 * bit_error_rate:.2f}%\")         print(f\"- SNR: {snr:.2f}dB\")      return {\"Bit Error Rate\": bit_error_rate, \"SNR (dB)\": snr, \"Throughput\": throughput} <p>We compare the algorithms' bit error rates from -20dB to 0dB.</p> In\u00a0[8]: Copied! <pre>test_env = ControlledSNREnvironment(0)\nresults_dict = {\"Algorithm\": []}\nn_timesteps = 13**4\nfor snr in torch.linspace(-20, 0, 20):\n    test_env.set_snr(snr)\n    for algorithm_name, devices in test_algorithms.items():\n        test_env.place(\n            {f\"{algorithm_name}-tx\": devices[\"tx\"]},\n            {f\"{algorithm_name}-rx\": devices[\"rx\"]},\n        )\n        device_logs = test_env.simulate(n_timesteps)\n        result = _analyze(device_logs, verbose=False)\n\n        results_dict[\"Algorithm\"].append(algorithm_name)\n\n        for k, v in result.items():\n            if k not in results_dict:\n                results_dict[k] = []\n            results_dict[k].append(v)\n</pre> test_env = ControlledSNREnvironment(0) results_dict = {\"Algorithm\": []} n_timesteps = 13**4 for snr in torch.linspace(-20, 0, 20):     test_env.set_snr(snr)     for algorithm_name, devices in test_algorithms.items():         test_env.place(             {f\"{algorithm_name}-tx\": devices[\"tx\"]},             {f\"{algorithm_name}-rx\": devices[\"rx\"]},         )         device_logs = test_env.simulate(n_timesteps)         result = _analyze(device_logs, verbose=False)          results_dict[\"Algorithm\"].append(algorithm_name)          for k, v in result.items():             if k not in results_dict:                 results_dict[k] = []             results_dict[k].append(v) <p>Finally, we visualize the results. We notice that the two algorithms exhibit very similar performance. There is no need to compare throughput, as they have the same throughput by design.</p> In\u00a0[9]: Copied! <pre>results_df = pd.DataFrame(results_dict)\n\nfig = px.line(\n    results_df,\n    x=\"SNR (dB)\",\n    y=\"Bit Error Rate\",\n    color=\"Algorithm\",\n    title=\"Bit Error Rate vs SNR\",\n    log_y=True,\n)\nImage(fig.to_image(format=\"png\"))\n</pre> results_df = pd.DataFrame(results_dict)  fig = px.line(     results_df,     x=\"SNR (dB)\",     y=\"Bit Error Rate\",     color=\"Algorithm\",     title=\"Bit Error Rate vs SNR\",     log_y=True, ) Image(fig.to_image(format=\"png\")) Out[9]: <p>We observe that the <code>DenseRadio</code> outperforms <code>DSSS-BPSK</code> in this case. Let's check that <code>DenseRadio</code> achives this improved bit error rate without comprimising on throughput.</p> In\u00a0[10]: Copied! <pre>throughput_df = results_df.groupby(\"Algorithm\")[\"Throughput\"].mean().reset_index()\nfig = px.bar(\n    throughput_df,\n    x=\"Algorithm\",\n    y=\"Throughput\",\n    log_y=False,\n    title=\"Bit Error Rate vs SNR\",\n)\nImage(fig.to_image(format=\"png\"))\n</pre> throughput_df = results_df.groupby(\"Algorithm\")[\"Throughput\"].mean().reset_index() fig = px.bar(     throughput_df,     x=\"Algorithm\",     y=\"Throughput\",     log_y=False,     title=\"Bit Error Rate vs SNR\", ) Image(fig.to_image(format=\"png\")) Out[10]:"},{"location":"Examples/6_compare_novel_vs_conventional/#compare-novel-and-conventional-radios","title":"Compare Novel and Conventional Radios\u00b6","text":""}]}